{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Knife MI analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import sklearn\n",
    "\n",
    "from utils import MolecularFeatureExtractor\n",
    "from models.model_paths import get_model_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATASET = \"ZINC\"\n",
    "LENGTH = 1024\n",
    "MDS_DIM = 0\n",
    "\n",
    "DESCRIPTORS = [\n",
    "            \"ecfp\",\n",
    "            \"estate\",\n",
    "            \"fcfp\",\n",
    "            \"erg\",\n",
    "            \"rdkit\",\n",
    "            \"topological\",\n",
    "            \"avalon\",\n",
    "            \"maccs\",\n",
    "            \"secfp\",\n",
    "            \"scaffoldkeys\",\n",
    "            \"cats\",\n",
    "            \"gobbi\",\n",
    "            \"pmapper\",\n",
    "            \"cats/3D\",\n",
    "            \"gobbi/3D\",\n",
    "            \"pmapper/3D\",\n",
    "            \"ScatteringWavelet\",\n",
    "        ]\n",
    "\n",
    "with open(f\"data/{DATASET}/smiles.json\", \"r\") as f:\n",
    "    smiles = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "FIGSIZE = 5\n",
    "fig,axes = plt.subplots(4,5,figsize=(FIGSIZE*5,FIGSIZE*4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i,d in enumerate(tqdm(DESCRIPTORS)):\n",
    "    embeddings = get_features(smiles, name=d, length=LENGTH, mds_dim=MDS_DIM, dataset=DATASET, feature_type=\"descriptor\", normalize=True)\n",
    "    pca = sklearn.decomposition.PCA(n_components=2)\n",
    "    embeddings_red = pca.fit_transform(embeddings)\n",
    "    #tsne = sklearn.manifold.TSNE(n_components=2, n_iter=250)\n",
    "    #embeddings_red = tsne.fit_transform(embeddings_red)\n",
    "    df = pd.DataFrame(embeddings_red, columns=[\"PC1\", \"PC2\"])\n",
    "    df[\"smiles\"] = smiles\n",
    "    sns.scatterplot(data=df, x=\"PC1\", y=\"PC2\",alpha=0.5, ax=axes[i])\n",
    "    axes[i].set_title(d)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embeddings.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(smiles)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_pca = [\"ChemBertMLM-5M\", \"ChemBertMTR-5M\", \"EdgePred\",\"GraphMVP\", \"AttributeMask\",\"Not-trained\"]\n",
    "MODELS = get_model_path(models=models_pca)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,len(models_pca),figsize=(len(models_pca)*5,5))\n",
    "for i,model in enumerate(models_pca):\n",
    "    embeddings = get_features(smiles, name=model, length=LENGTH, mds_dim=MDS_DIM, dataset=DATASET, feature_type=\"model\", normalize=True, path = MODELS.get(model, None))\n",
    "    # nromalize embeddings\n",
    "    embeddings = (embeddings - embeddings.mean(axis=0))/(embeddings.std(axis=0) +1e-8)\n",
    "    pca = sklearn.decomposition.PCA(n_components=2)\n",
    "    embeddings_pca = pca.fit_transform(embeddings)\n",
    "    df = pd.DataFrame(embeddings_pca, columns=[\"PC1\", \"PC2\"])\n",
    "    df[\"smiles\"] = smiles\n",
    "    sns.scatterplot(data=df, x=\"PC1\", y=\"PC2\",alpha=0.05, ax = axes[i])\n",
    "    axes[i].set_title(model)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_df_loss_cond = []\n",
    "full_df_loss_marg = []\n",
    "RESULTS_PATH = f\"results/{DATASET}/{LENGTH}/{MDS_DIM}\"\n",
    "dir_path = os.path.join(RESULTS_PATH, \"losses\")\n",
    "\n",
    "for file in tqdm(os.listdir(dir_path)):\n",
    "    #one plot for each model showing the loss on all descriptors. Files are {model}_{descriptor}_{run}_XY.csv\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_split = file[:-4].split(\"_\")\n",
    "        if file_split[0] == DATASET and file_split[-2] == str(LENGTH):\n",
    "            if file_split[-1] == \"marg\":\n",
    "                model, descriptor = file.split(\"_\")[:2]\n",
    "                df_tmp = pd.read_csv(os.path.join(dir_path, file))\n",
    "                full_df_loss_marg.append(df_tmp)\n",
    "            else:\n",
    "                model, descriptor = file.split(\"_\")[:2]\n",
    "                df_tmp = pd.read_csv(os.path.join(dir_path, file))\n",
    "                full_df_loss_cond.append(df_tmp)\n",
    "\n",
    "full_df_loss_cond = pd.concat(full_df_loss_cond)\n",
    "full_df_loss_marg = pd.concat(full_df_loss_marg)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_rows = np.ceil(full_df_loss_cond.Y.nunique()/5).astype(int)+1\n",
    "n_cols = 5\n",
    "fig, axes = plt.subplots(n_rows,n_cols,figsize=(n_cols*4,4*n_rows))\n",
    "axes = axes.flatten()\n",
    "for i, model in enumerate(tqdm(full_df_loss_marg.X.unique())):\n",
    "    df_tmp = full_df_loss_marg[full_df_loss_marg.X == model]\n",
    "    sns.lineplot(data=df_tmp, x=\"epoch\", y=\"marg_ent\", hue=\"X\", ax=axes[i], estimator=None, errorbar= None, n_boot=0, legend=False)\n",
    "    axes[i].set_title(model)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"Marginal entropy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove EdgePred\n",
    "full_df_loss_cond = full_df_loss_cond[full_df_loss_cond.Y != \"EdgePred\"]\n",
    "full_df_loss_cond = full_df_loss_cond[full_df_loss_cond.X != \"EdgePred\"]\n",
    "\n",
    "full_df_loss_margin = full_df_loss_marg[full_df_loss_marg.X != \"EdgePred\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_rows = full_df_loss_cond.Y.nunique()\n",
    "n_cols = 2\n",
    "fig, axes = plt.subplots(n_rows,n_cols,figsize=(n_cols*4,4*n_rows))\n",
    "\n",
    "\n",
    "for i, model in enumerate(tqdm(full_df_loss_cond.Y.unique())):\n",
    "    df_tmp = full_df_loss_cond[(full_df_loss_cond.Y == model) & (full_df_loss_cond.direction == \"X->Y\")]\n",
    "    sns.lineplot(data=df_tmp, x=\"epoch\", y=\"cond_ent\", hue=\"X\", ax=axes[i,0], estimator=None, errorbar= None, n_boot=0, legend=False)\n",
    "    axes[i,0].set_title(model)\n",
    "    axes[i,0].set_xlabel(\"\")\n",
    "    axes[i,0].set_ylabel(\"X->Y H(Y|X)\")\n",
    "\n",
    "    df_tmp = full_df_loss_cond[(full_df_loss_cond.Y == model) & (full_df_loss_cond.direction == \"Y->X\")]\n",
    "\n",
    "    sns.lineplot(data=df_tmp, x=\"epoch\", y=\"cond_ent\", hue=\"X\", ax=axes[i,1], estimator=None, errorbar= None, n_boot=0, legend=False)\n",
    "    axes[i,1].set_title(model)\n",
    "    axes[i,1].set_xlabel(\"\")\n",
    "    axes[i,1].set_ylabel(\"Y->X H(X|Y)\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MI between descriptors and embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "all_df = []\n",
    "for file in os.listdir(RESULTS_PATH):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_split = file[:-4].split(\"_\")\n",
    "        if file_split[0] == DATASET and file_split[-1] == str(LENGTH):\n",
    "            all_df.append(pd.read_csv(os.path.join(RESULTS_PATH, file)))\n",
    "df = pd.concat(all_df)\n",
    "\n",
    "#df =df[df.Y.isin(DESCRIPTORS)]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Clustermap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"I(Y->X)/dim\"] = df[\"I(Y->X)\"]/df[\"X_dim\"]\n",
    "df[\"I(X->Y)/dim\"] = df[\"I(X->Y)\"]/df[\"Y_dim\"]\n",
    "\n",
    "df[\"I(Y->X)/I(X)\"] = df[\"I(Y->X)\"]/df[\"I(X)\"]\n",
    "df[\"I(X->Y)/I(Y)\"] = df[\"I(X->Y)\"]/df[\"I(Y)\"]\n",
    "\n",
    "df[\"I(Y->X)/I(X)\"] = df[\"I(Y->X)\"]/df[\"I(X)\"]\n",
    "df[\"I(X->Y)/I(Y)\"] = df[\"I(X->Y)\"]/df[\"I(Y)\"]\n",
    "\n",
    "\n",
    "\n",
    "df[\"I(Y->X) - I(X->Y)\"] =  df[\"I(Y->X)\"]-df[\"I(X->Y)\"]\n",
    "df[\"I(Y->X)/dim - I(X->Y)/dim\"] = df[\"I(Y->X)/dim\"]-df[\"I(X->Y)/dim\"]\n",
    "df[\"I(Y->X)/I(X) - I(X->Y)/I(Y)\"] = df[\"I(Y->X)/I(X)\"]-df[\"I(X->Y)/I(Y)\"]\n",
    "\n",
    "df[\"I(Y->X) / I(X->Y)\"] =  df[\"I(Y->X)\"]/(df[\"I(X->Y)\"] + 1e-8)\n",
    "df[\"I(Y->X)/dim / I(X->Y)/dim\"] = df[\"I(Y->X)/dim\"]/(df[\"I(X->Y)/dim\"] + 1e-8)\n",
    "df[\"I(Y->X)/I(X) / I(X->Y)/I(Y)\"] = df[\"I(Y->X)/I(X)\"]/(df[\"I(X->Y)/I(Y)\"] + 1e-8)\n",
    "\n",
    "df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.X = df.X.apply(lambda x: x[:-4])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[(df.Y!= \"EdgePred\") & (\"EdgePred\" != df.X)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,5))\n",
    "sns.scatterplot(data=df, y=\"X_dim\", x=\"X\", hue=\"X\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keys = [\n",
    "    \"I(Y->X)\", \"I(X->Y)\", \"I(Y->X)/dim\", \"I(X->Y)/dim\",\n",
    "    \"I(Y->X) - I(X->Y)\", \"I(Y->X)/dim - I(X->Y)/dim\",\n",
    "]\n",
    "\n",
    "for key in keys:\n",
    "    df[key + \"_normed\"] = df.apply(lambda x: x[key] - df[(df.Y == \"Not-trained\") & (df.X == x.X)][key].values[0], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(15, 5), sharex=True)\n",
    "\n",
    "sns.scatterplot(data=df, y=\"I(Y->X)\", x=\"X_dim\", hue=\"X\", ax=axes[0], legend=False)\n",
    "\n",
    "sns.scatterplot(data=df, y=\"I(Y->X)/dim\", x=\"X_dim\", hue=\"X\", ax=axes[1], legend=False)\n",
    "\n",
    "sns.scatterplot(data=df, y=\"I(Y->X)/I(X)\", x=\"X_dim\", hue=\"X\", ax=axes[2], legend=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(15, 5), sharex=True)\n",
    "\n",
    "sns.scatterplot(data=df, y=\"I(X->Y)\", x=\"Y_dim\", hue=\"Y\", ax=axes[0], legend=False)\n",
    "sns.scatterplot(data=df, y=\"I(X->Y)/dim\", x=\"Y_dim\", hue=\"Y\", ax=axes[1], legend=False)\n",
    "sns.scatterplot(data=df, y=\"I(X->Y)/I(Y)\", x=\"Y_dim\", hue=\"Y\", ax=axes[2], legend=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_cmap(df, keys, cmap = \"copper\", vmin = None, vmax = None, center = None):\n",
    "    if vmax is None:\n",
    "        vmax = [None]*len(keys)\n",
    "    if vmin is None:\n",
    "        vmin = [None]*len(keys)\n",
    "    for i, key in enumerate(keys):\n",
    "        df_pivot = df.pivot_table(index=\"X\", columns=\"Y\", values=key, aggfunc=\"mean\")\n",
    "        from scipy.cluster.hierarchy import linkage\n",
    "        link = linkage(df_pivot, method=\"ward\")\n",
    "        cluster = sns.clustermap(\n",
    "            df_pivot, row_linkage=link, col_linkage=link,\n",
    "            cmap=cmap, figsize=(8,8), vmin=vmin[i], vmax=vmax[i], center=center\n",
    "        )\n",
    "        cluster.savefig(\"fig/cluster_{}.png\".format(i))\n",
    "        plt.clf()\n",
    "\n",
    "    import matplotlib.image as mpimg\n",
    "    fig, axes = plt.subplots(1,len(keys), figsize=(8*len(keys),8))\n",
    "    for i, key in enumerate(keys):\n",
    "        axes[i].imshow(mpimg.imread(\"fig/cluster_{}.png\".format(i)))\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(key)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_cmap(\n",
    "    df,\n",
    "    [\"I(X->Y)\", \"I(X->Y)/dim\", \"I(X->Y)/I(Y)\"],\n",
    "    cmap=\"viridis\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(\n",
    "    df,\n",
    "    [\"I(Y->X) - I(X->Y)\", \"I(Y->X)/dim - I(X->Y)/dim\", \"I(Y->X)/I(X) - I(X->Y)/I(Y)\"],\n",
    "    cmap=\"seismic\",\n",
    "    center=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(\n",
    "    df,\n",
    "    [\"I(Y->X) / I(X->Y)\", \"I(Y->X)/dim / I(X->Y)/dim\", \"I(Y->X)/I(X) / I(X->Y)/I(Y)\"],\n",
    "    cmap=\"seismic\",\n",
    "    center=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "sns.boxplot(data=df, x=\"X\", y=\"I(Y->X)\", hue=\"Y\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(data=df[df.Y != \"Not-trained\"], x=\"X\", y=\"I(Y->X)\", hue=\"Y\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T18:49:57.329069535Z",
     "start_time": "2023-11-10T18:49:57.296239770Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": "        Drug_ID                                               Drug  Y\n799    Drug 801                                         CC(=O)[O-]  0\n889    Drug 891         Cc1[nH+]cc2n1-c1ccc(Cl)cc1C(c1ccccc1F)=NC2  0\n145    Drug 146                 O=C1CN2Cc3c(ccc(Cl)c3Cl)[NH+]=C2N1  0\n1034  Drug 1038  Cc1nnc(C(=O)NC(C)(C)c2nc(C(=O)NCc3ccc(F)cc3)c(...  0\n1282  Drug 1288                         CCN(CC)C(=S)SSC(=S)N(CC)CC  0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Drug_ID</th>\n      <th>Drug</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>799</th>\n      <td>Drug 801</td>\n      <td>CC(=O)[O-]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>Drug 891</td>\n      <td>Cc1[nH+]cc2n1-c1ccc(Cl)cc1C(c1ccccc1F)=NC2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>Drug 146</td>\n      <td>O=C1CN2Cc3c(ccc(Cl)c3Cl)[NH+]=C2N1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1034</th>\n      <td>Drug 1038</td>\n      <td>Cc1nnc(C(=O)NC(C)(C)c2nc(C(=O)NCc3ccc(F)cc3)c(...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1282</th>\n      <td>Drug 1288</td>\n      <td>CCN(CC)C(=S)SSC(=S)N(CC)CC</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install networkx==2.8.8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.0+cu118.html --force"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from tdc.single_pred import Tox\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datamol as dm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from evaluation import get_dataloaders, Feed_forward\n",
    "from precompute_3d import precompute_3d\n",
    "\n",
    "df = Tox(name=\"ClinTox\").get_data()\n",
    "mols, smiles = precompute_3d(df[\"Drug\"].to_numpy(), \"ClinTox\")\n",
    "valid_indices = []\n",
    "mols_valid = []\n",
    "i_mol = 0\n",
    "for i,s in enumerate(df[\"Drug\"]):\n",
    "    if dm.to_smiles(dm.to_mol(s), True, False) in smiles and not \"*\" in s:\n",
    "        df[\"Drug\"].iloc[i] = dm.to_smiles(dm.to_mol(s), True, False)\n",
    "        valid_indices.append(i)\n",
    "        mols_valid.append(mols[i_mol])\n",
    "        i_mol += 1\n",
    "\n",
    "df = df.iloc[valid_indices]\n",
    "df[\"Mol\"] = mols_valid\n",
    "\n",
    "smiles = df[\"Drug\"].to_numpy()\n",
    "y = df[\"Y\"].to_numpy()\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "df.sample(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_expe(model_path = \"backbone_pretrained_models/GraphLog/Contextual.pth\", desc_name=\"\", n_epochs = 100, plot=False):\n",
    "    dataloader_train, dataloader_test, input_dim = get_dataloaders(smiles_train, y_train, smiles_test, y_test, desc_name=desc_name, model_path=model_path)\n",
    "    model = Feed_forward(\n",
    "        input_dim = input_dim,\n",
    "        hidden_dim = 128,\n",
    "        output_dim = 1,\n",
    "        n_layers = 1,\n",
    "        d_rate=0.3,\n",
    "        norm=\"batch\"\n",
    "    )\n",
    "    model.train_model(dataloader_train, dataloader_test, n_epochs=n_epochs)\n",
    "    model_name = \"None\" if model_path==\"None\" else model_path.split(\"/\")[-2] + \" \"\n",
    "    if plot:\n",
    "        model.plot_loss(title = model_name + \" \" + desc_name)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "descriptors = [\n",
    "            \"physchem\",\n",
    "            \"ecfp-count\",\n",
    "            \"ecfp\",\n",
    "            \"estate\",\n",
    "            \"erg\",\n",
    "            \"rdkit\",\n",
    "            \"topological\",\n",
    "            \"avalon\",\n",
    "            \"maccs\",\n",
    "            \"scaffoldkeys\",\n",
    "            \"cats\",\n",
    "            \"default\",\n",
    "            \"gobbi\",\n",
    "            \"pmapper\",\n",
    "            \"cats/3D\",\n",
    "            \"gobbi/3D\",\n",
    "            \"pmapper/3D\",\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mi = pd.read_csv(\"resultsClinTox.csv\").groupby([\"X\", \"Y\"])[\"I(X->Y)\"].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "df_desc = {\"descriptor\":[], \"best_acc\": [], \"best_f1\":[], \"best_roc\":[], \"best_aucpr\":[]}\n",
    "\n",
    "N_RUNS = 5\n",
    "p_bar = tqdm(total=len(descriptors) * N_RUNS, desc=\"Fine tuning\",position=0, leave=True)\n",
    "\n",
    "for d in descriptors:\n",
    "        dataloader_train, dataloader_test, input_dim = get_dataloaders(\n",
    "            df_train.Drug, y_train, df_test.Drug, y_test,df_train[\"Mol\"], df_test[\"Mol\"], desc_name=d, model_path=\"None\")\n",
    "        for _ in range(N_RUNS):\n",
    "            df_desc[\"descriptor\"].append(d)\n",
    "            model = Feed_forward(\n",
    "                input_dim = input_dim,\n",
    "                hidden_dim = 128,\n",
    "                output_dim = 1,\n",
    "                n_layers = 1,\n",
    "                d_rate=0.3,\n",
    "                norm=\"batch\"\n",
    "            )\n",
    "            model.train_model(dataloader_train, dataloader_test, n_epochs=300)\n",
    "            best_acc = np.max(model.test_acc)\n",
    "            df_desc[\"best_acc\"].append(best_acc)\n",
    "            df_desc[\"best_f1\"].append(np.max(model.test_f1))\n",
    "            df_desc[\"best_roc\"].append(np.max(model.test_roc))\n",
    "            df_desc[\"best_aucpr\"].append(np.max(model.test_aucpr))\n",
    "            p_bar.update(1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_desc = pd.DataFrame(df_desc)\n",
    "df_desc\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_PATH = \"backbone_pretrained_models\"\n",
    "MODELS = {}\n",
    "# For every directory in the folder\n",
    "for model_name in os.listdir(MODEL_PATH):\n",
    "    # For every file in the directory\n",
    "    for file_name in os.listdir(os.path.join(MODEL_PATH, model_name)):\n",
    "        # If the file is a .pth file\n",
    "        if file_name.endswith(\".pth\"):\n",
    "            MODELS[model_name] = os.path.join(MODEL_PATH, model_name, file_name)\n",
    "MODELS[\"Not-trained\"] = \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "df_model = {\"model\":[], \"best_acc\": [], \"best_f1\":[], \"best_roc\":[], \"best_aucpr\":[]}\n",
    "\n",
    "N_RUNS = 5\n",
    "p_bar = tqdm(total=len(MODELS) * N_RUNS, desc=\"Fine tuning\",position=0, leave=True)\n",
    "\n",
    "for model_name, model_path in MODELS.items():\n",
    "        dataloader_train, dataloader_test, input_dim = get_dataloaders(\n",
    "            df_train.Drug, y_train, df_test.Drug, y_test,df_train[\"Mol\"], df_test[\"Mol\"], desc_name=\"None\", model_path=model_path)\n",
    "        for _ in range(N_RUNS):\n",
    "            df_model[\"model\"].append(model_name)\n",
    "            model = Feed_forward(\n",
    "                input_dim = input_dim,\n",
    "                hidden_dim = 128,\n",
    "                output_dim = 1,\n",
    "                n_layers = 1,\n",
    "                d_rate=0.3,\n",
    "                norm=\"batch\"\n",
    "            )\n",
    "            model.train_model(dataloader_train, dataloader_test, n_epochs=300)\n",
    "            best_acc = np.max(model.test_acc)\n",
    "            df_model[\"best_acc\"].append(best_acc)\n",
    "            df_model[\"best_f1\"].append(np.max(model.test_f1))\n",
    "            df_model[\"best_roc\"].append(np.max(model.test_roc))\n",
    "            df_model[\"best_aucpr\"].append(np.max(model.test_aucpr))\n",
    "            p_bar.update(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(32,16))\n",
    "for i,metric in enumerate([\"best_f1\", \"best_roc\", \"best_aucpr\"]):\n",
    "    sns.barplot(data=df_desc.sort_values(\"best_aucpr\"), x=\"descriptor\", y=metric, hue=\"descriptor\", ax = axes[i])\n",
    "    axes[i].set_ylim(max(0,df_desc[metric].min()-0.05), min(1,df_desc[metric].max() + 0.05))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(df_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(32,16))\n",
    "for i,metric in enumerate([\"best_f1\", \"best_roc\", \"best_aucpr\"]):\n",
    "    sns.barplot(data=df_model.sort_values(\"best_aucpr\"), x=\"model\", y=metric, hue=\"model\", ax = axes[i])\n",
    "    axes[i].set_ylim(max(0,df_desc[metric].min()-0.05), min(1,df_desc[metric].max() + 0.05))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mi = pd.read_csv(\"resultsClinTox.csv\")\n",
    "df_mi[\"I(X->Y)_normed\"] = df_mi.apply(lambda x: x[\"I(X->Y)\"] - df_mi[(df.Y == \"Not-trained\") & (df_mi.X == x.X)][\"I(X->Y)\"].values[0], axis=1)\n",
    "df_mi[\"I(Y->X)_normed\"] = df_mi.apply(lambda x: x[\"I(Y->X)\"] - df_mi[(df.Y == \"Not-trained\") & (df_mi.X == x.X)][\"I(Y->X)\"].values[0], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hue_order = df_model.model.unique()\n",
    "fig, axess = plt.subplots(len(descriptors),3,figsize=(3*7,len(descriptors)*7))\n",
    "first = True\n",
    "for descriptor, axes in zip(descriptors, axess):\n",
    "    df_plot = df_model[~(df_model.model.isin([\"Not-trained\", \"EdgePred\"]))].merge(df_mi, left_on=\"model\", right_on=\"Y\").drop(columns=[\"Y\"]).rename(columns={\"X\":\"descriptor\"})\n",
    "    df_plot = df_plot[df_plot.descriptor == descriptor]\n",
    "    for i,(metric, ax) in enumerate(zip([\"best_f1\", \"best_roc\", \"best_aucpr\"], axes)):\n",
    "        #Scatterplot with linear regression amd corr-coefficient\n",
    "        sns.regplot(data=df_plot, y=metric, x=\"I(X->Y)_normed\", ax =ax, scatter_kws={\"alpha\":0.5}, line_kws={\"color\":\"red\"})\n",
    "        #display correlation coefficient\n",
    "        corr = df_plot[[metric, \"I(X->Y)_normed\"]].corr().iloc[0,1]\n",
    "        ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "        ax.set_title(\"I(X->Y)_normed \" + descriptor + \" \" + str(df_desc[df_desc.descriptor == descriptor][metric].mean())[:4])\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hue_order = df_model.model.unique()\n",
    "fig, axess = plt.subplots(len(descriptors),3,figsize=(3*7,len(descriptors)*7))\n",
    "first = True\n",
    "for descriptor, axes in zip(descriptors, axess):\n",
    "    df_plot = df_model[~(df_model.model.isin([\"Not-trained\", \"EdgePred\"]))].merge(df_mi, left_on=\"model\", right_on=\"Y\").drop(columns=[\"Y\"]).rename(columns={\"X\":\"descriptor\"})\n",
    "    df_plot = df_plot[df_plot.descriptor == descriptor]\n",
    "    for i,(metric, ax) in enumerate(zip([\"best_f1\", \"best_roc\", \"best_aucpr\"], axes)):\n",
    "        #Scatterplot with linear regression amd corr-coefficient\n",
    "        sns.regplot(data=df_plot, y=metric, x=\"I(Y->X)_normed\", ax =ax, scatter_kws={\"alpha\":0.5}, line_kws={\"color\":\"red\"})\n",
    "        #display correlation coefficient\n",
    "        corr = df_plot[[metric, \"I(Y->X)_normed\"]].corr().iloc[0,1]\n",
    "        ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "\n",
    "        ax.set_title(\"I(Y->X)_normed \" +descriptor + \" \" + str(df_desc[df_desc.descriptor == descriptor][metric].mean())[:4])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now also consider a score that aggregates all MIs by suming all normalized MIs weigthed with the descriptor's best performance\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_plot = df_model[~(df_model.model.isin([\"Not-trained\", \"EdgePred\"]))].merge(df_mi, left_on=\"model\", right_on=\"Y\").drop(columns=[\"Y\"]).rename(columns={\"X\":\"descriptor\"})\n",
    "df_tmp_descriptors = df_desc.rename(columns={k: k+\"_desc\" for k in [\"best_f1\", \"best_roc\", \"best_aucpr\"]})\n",
    "df_plot = df_plot.merge(df_tmp_descriptors, left_on=\"descriptor\", right_on=\"descriptor\")\n",
    "df_plot[\"sum_I(X->Y)_item\"] = df_plot[\"I(X->Y)_normed\"] * df_plot[\"best_aucpr_desc\"]\n",
    "df_plot[\"sum_I(Y->X)_item\"] = df_plot[\"I(Y->X)_normed\"] * df_plot[\"best_aucpr_desc\"]\n",
    "\n",
    "sum_values = df_plot.groupby(\"model\")[[\"sum_I(X->Y)_item\", \"sum_I(Y->X)_item\"]].sum().reset_index().rename(columns={\"sum_I(X->Y)_item\":\"sum_I(X->Y)\", \"sum_I(Y->X)_item\":\"sum_I(Y->X)\"})\n",
    "\n",
    "df_plot = df_plot.merge(sum_values, left_on=\"model\", right_on=\"model\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(20, 5), sharex=True)\n",
    "for i, (ax, metric) in enumerate(zip(axes, [\"best_f1\", \"best_roc\", \"best_aucpr\"])):\n",
    "    sns.scatterplot(data=df_plot, y=metric, x=\"sum_I(X->Y)\", hue=\"model\", palette=\"Set3\", alpha=0.5, ax=ax, legend=i==0)\n",
    "    #corr coefficient\n",
    "    corr = df_plot[[metric, \"sum_I(X->Y)\"]].corr().iloc[0,1]\n",
    "    ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(metric.split(\"_\")[1])\n",
    "\n",
    "axes[1].set_xlabel(\n",
    "    \"$\\sum_{desc\\in descriptors} [\\mathcal{I} ( desc->model ) - \\mathcal{I}(desc->model_{NT})$] metric$(desc)$\"\n",
    ")\n",
    "\n",
    "fig.suptitle(\"$\\mathcal{I} ( desc->model )$ score's correlation to the best performance of each evaluated model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(20, 5), sharex=True)\n",
    "for i, (ax, metric) in enumerate(zip(axes, [\"best_f1\", \"best_roc\", \"best_aucpr\"])):\n",
    "    sns.scatterplot(data=df_plot, y=metric, x=\"sum_I(Y->X)\", hue=\"model\", palette=\"Set3\", alpha=0.5, ax=ax, legend=i==0)\n",
    "    #corr coefficient\n",
    "    corr = df_plot[[metric, \"sum_I(Y->X)\"]].corr().iloc[0,1]\n",
    "    ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(metric.split(\"_\")[1])\n",
    "\n",
    "axes[1].set_xlabel(\n",
    "    \"$\\sum_{desc\\in descriptors} [\\mathcal{I} ( model-> desc) - \\mathcal{I}(model_{NT} -> desc)$] metric$(desc)$\"\n",
    ")\n",
    "\n",
    "fig.suptitle(\"$\\mathcal{I} ( model-> desc)$ score's correlation to the best performance of each evaluated model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_plot[\"compression\"] = df_plot[\"sum_I(Y->X)\"] - df_plot[\"sum_I(X->Y)\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(20, 5), sharex=True)\n",
    "for i, (ax, metric) in enumerate(zip(axes, [\"best_f1\", \"best_roc\", \"best_aucpr\"])):\n",
    "    sns.scatterplot(data=df_plot, y=metric, x=\"compression\", hue=\"model\", palette=\"Set3\", alpha=0.5, ax=ax, legend=i==0)\n",
    "    #corr coefficient\n",
    "    corr = df_plot[[metric, \"compression\"]].corr().iloc[0,1]\n",
    "    ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(metric.split(\"_\")[1])\n",
    "\n",
    "axes[1].set_xlabel(\n",
    "    \"$\\sum_{desc\\in descriptors} [\\mathcal{I} ( model-> desc) - \\mathcal{I}(model_{NT} -> desc)$] metric$(desc)$\"\n",
    ")\n",
    "\n",
    "fig.suptitle(\"$\\mathcal{I} ( model-> desc)$ score's correlation to the best performance of each evaluated model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_plot[\"compression_dummy\"] = (df_plot[\"sum_I(X->Y)\"] - df_plot[\"sum_I(X->Y)\"].max())/(df_plot[\"sum_I(X->Y)\"].min() - df_plot[\"sum_I(X->Y)\"].max()) - (df_plot[\"sum_I(Y->X)\"] - df_plot[\"sum_I(Y->X)\"].max())/(df_plot[\"sum_I(Y->X)\"].min() - df_plot[\"sum_I(Y->X)\"].max())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(20, 5), sharex=True)\n",
    "for i, (ax, metric) in enumerate(zip(axes, [\"best_f1\", \"best_roc\", \"best_aucpr\"])):\n",
    "    sns.scatterplot(data=df_plot, y=metric, x=\"compression_dummy\", hue=\"model\", palette=\"Set3\", alpha=0.5, ax=ax, legend=i==0)\n",
    "    #corr coefficient\n",
    "    corr = df_plot[[metric, \"compression_dummy\"]].corr().iloc[0,1]\n",
    "    ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(metric.split(\"_\")[1])\n",
    "\n",
    "axes[1].set_xlabel(\n",
    "    \"Weird compression stuff\"\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Really weird compression stuff\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import ZINC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = ZINC(root='/tmp/ZINC', subset=True, split='val')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tdc_dataset import get_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_dataset(dataset: str):\n",
    "    try:\n",
    "        df = correspondancy_dict[dataset](name=dataset).get_data()\n",
    "    except:\n",
    "        label_list = retrieve_label_name_list(dataset)\n",
    "        df = correspondancy_dict[dataset](name=dataset, label_name=label_list[0]).get_data()\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = get_dataset(\"QM7b\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from moleculenet_encoding import mol_to_graph_data_obj_simple"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"data/HIV/smiles.json\", \"r\") as f:\n",
    "    smiles = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mols = dm.read_sdf(\"data/HIV/preprocessed.sdf\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for s, mol in zip(tqdm(smiles), mols):\n",
    "    s2 = dm.to_smiles(mol, True, False)\n",
    "    try:\n",
    "        mol_to_graph_data_obj_simple(dm.to_mol(s))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smiles = [dm.to_smiles(mol, True, False) for mol in mols]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"data/HIV/smiles.json\", \"w\") as f:\n",
    "    json.dump(smiles, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
