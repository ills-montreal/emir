{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Knife MI analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATASET = \"HIV\"\n",
    "LENGTH = 2048"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_df_loss = []\n",
    "for file in os.listdir(\"results/losses\"):\n",
    "    #one plot for each model showing the loss on all descriptors. Files are {model}_{descriptor}_{run}_XY.csv\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_split = file[:-4].split(\"_\")\n",
    "        if file_split[0] == DATASET and file_split[-2] == str(LENGTH):\n",
    "            model, descriptor = file.split(\"_\")[:2]\n",
    "            df_tmp = pd.read_csv(os.path.join(\"results/losses\", file))\n",
    "            full_df_loss.append(df_tmp)\n",
    "\n",
    "full_df_loss = pd.concat(full_df_loss)\n",
    "full_df_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_rows = full_df_loss.Y.nunique()\n",
    "\n",
    "fig, axes = plt.subplots(2,n_rows,figsize=(4*n_rows,8))\n",
    "\n",
    "for i, model in enumerate(full_df_loss.Y.unique()):\n",
    "    df_tmp = full_df_loss[(full_df_loss.Y == model) & (full_df_loss.direction == \"X->Y\")]\n",
    "    sns.lineplot(data=df_tmp, x=\"epoch\", y=\"loss\", hue=\"X\", ax=axes[0,i])\n",
    "    axes[0,i].set_title(model)\n",
    "    axes[0,i].set_xlabel(\"\")\n",
    "    axes[0,i].set_ylabel(\"X->Y loss\")\n",
    "\n",
    "    df_tmp = full_df_loss[(full_df_loss.Y == model) & (full_df_loss.direction == \"Y->X\")]\n",
    "    sns.lineplot(data=df_tmp, x=\"epoch\", y=\"loss\", hue=\"X\", ax=axes[1,i])\n",
    "    axes[1,i].set_xlabel(\"Epoch\")\n",
    "    if i== 0:\n",
    "        axes[0,i].set_ylabel(\"X->Y loss\")\n",
    "        axes[1,i].set_ylabel(\"Y->X loss\")\n",
    "    else:\n",
    "        axes[0,i].set_ylabel(\"\")\n",
    "        axes[1,i].set_ylabel(\"\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MI between descriptors and embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "all_df = []\n",
    "for file in os.listdir(\"results\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_split = file[:-4].split(\"_\")\n",
    "        if file_split[0] == DATASET and file_split[-1] == str(LENGTH):\n",
    "            all_df.append(pd.read_csv(os.path.join(\"results\", file)))\n",
    "df = pd.concat(all_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df.isna().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustermap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dim_desc = {}\n",
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "for file in tqdm(os.listdir(\"data/{}\".format(DATASET))):\n",
    "    if file.endswith(\".npy\"):\n",
    "        if file[:-4].split('_')[1] == str(LENGTH):\n",
    "            desc = file.split('_')[0]\n",
    "            desc_val = np.load(\"data/{}/{}\".format(DATASET, file), mmap_mode=\"r\")\n",
    "            dim_desc[desc + str(LENGTH)] = desc_val.shape[1]\n",
    "dim_desc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"I(Y->X)/dim\"] = df.apply(lambda x: x[\"I(Y->X)\"]/dim_desc[x.X], axis=1)\n",
    "df[\"I(X->Y)/dim\"] = df.apply(lambda x: x[\"I(X->Y)\"]/300, axis=1)\n",
    "\n",
    "df[\"I(Y->X)/logdim\"] = df.apply(lambda x: x[\"I(Y->X)\"]/np.log(dim_desc[x.X]), axis=1)\n",
    "df[\"I(X->Y)/logdim\"] = df.apply(lambda x: x[\"I(X->Y)\"]/np.log(300), axis=1)\n",
    "\n",
    "df[\"I(Y->X) - I(X->Y)\"] =  df[\"I(Y->X)\"]-df[\"I(X->Y)\"]\n",
    "df[\"I(Y->X)/dim - I(X->Y)/dim\"] = df[\"I(Y->X)/dim\"]-df[\"I(X->Y)/dim\"]\n",
    "df[\"I(Y->X)/logdim - I(X->Y)/logdim\"] = df[\"I(Y->X)/logdim\"]-df[\"I(X->Y)/logdim\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keys = [\n",
    "    \"I(Y->X)\", \"I(X->Y)\", \"I(Y->X)/dim\", \"I(X->Y)/dim\", \"I(Y->X)/logdim\", \"I(X->Y)/logdim\",\n",
    "    \"I(Y->X) - I(X->Y)\", \"I(Y->X)/dim - I(X->Y)/dim\", \"I(Y->X)/logdim - I(X->Y)/logdim\"\n",
    "]\n",
    "\n",
    "for key in keys:\n",
    "    df[key + \"_normed\"] = df.apply(lambda x: x[key] - df[(df.Y == \"Not-trained\") & (df.X == x.X)][key].values[0], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_cmap(df, key):\n",
    "    std_cmap = sns.clustermap(\n",
    "        df.pivot_table(index=\"X\", columns=\"Y\", values=key, aggfunc=\"mean\"),\n",
    "        cmap=\"viridis\", figsize=(8,8)\n",
    "    )\n",
    "    std_cmap.savefig(\"fig/std_cmap.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    norm_cmap = sns.clustermap(\n",
    "        df.pivot_table(index=\"X\", columns=\"Y\", values=f\"{key}_normed\", aggfunc=\"mean\"),\n",
    "        cmap=\"coolwarm\", center=0, figsize=(8,8),\n",
    "    )\n",
    "    #save temp images to then display both in a subplot\n",
    "    norm_cmap.savefig(\"fig/norm_cmap.png\")\n",
    "    plt.clf()\n",
    "    import matplotlib.image as mpimg\n",
    "    fig, axes = plt.subplots(1,2, figsize=(16,8))\n",
    "    axes[0].imshow(mpimg.imread(\"fig/std_cmap.png\"))\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[0].set_title(\"Standard MI\")\n",
    "    axes[1].imshow(mpimg.imread(\"fig/norm_cmap.png\"))\n",
    "    axes[1].axis(\"off\")\n",
    "    axes[1].set_title(\"Normalized MI\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(df, \"I(X->Y)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(df, \"I(Y->X)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(df, \"I(Y->X) - I(X->Y)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(df, \"I(X->Y)/dim\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(df, \"I(Y->X)/dim\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(df, \"I(Y->X)/logdim\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(df, \"I(X->Y)/logdim\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cmap(df, \"I(Y->X)/logdim - I(X->Y)/logdim\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dim_desc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.clustermap(\n",
    "    df.pivot_table(index=\"X\", columns=\"Y\", values=\"I(Y->X)_normed\", aggfunc=\"mean\"),\n",
    "    cmap=\"coolwarm\", figsize=(8,8), center=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalize each I(X->Y) by the value of I(X->Y) for the untrained model by substracting it\n",
    "df[\"I(X->Y)_normed\"] = df.apply(lambda x: x[\"I(X->Y)\"] - df[(df.Y == \"Not-trained\") & (df.X == x.X)][\"I(X->Y)\"].values[0], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T18:49:57.329069535Z",
     "start_time": "2023-11-10T18:49:57.296239770Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": "        Drug_ID                                               Drug  Y\n799    Drug 801                                         CC(=O)[O-]  0\n889    Drug 891         Cc1[nH+]cc2n1-c1ccc(Cl)cc1C(c1ccccc1F)=NC2  0\n145    Drug 146                 O=C1CN2Cc3c(ccc(Cl)c3Cl)[NH+]=C2N1  0\n1034  Drug 1038  Cc1nnc(C(=O)NC(C)(C)c2nc(C(=O)NCc3ccc(F)cc3)c(...  0\n1282  Drug 1288                         CCN(CC)C(=S)SSC(=S)N(CC)CC  0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Drug_ID</th>\n      <th>Drug</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>799</th>\n      <td>Drug 801</td>\n      <td>CC(=O)[O-]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>Drug 891</td>\n      <td>Cc1[nH+]cc2n1-c1ccc(Cl)cc1C(c1ccccc1F)=NC2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>Drug 146</td>\n      <td>O=C1CN2Cc3c(ccc(Cl)c3Cl)[NH+]=C2N1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1034</th>\n      <td>Drug 1038</td>\n      <td>Cc1nnc(C(=O)NC(C)(C)c2nc(C(=O)NCc3ccc(F)cc3)c(...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1282</th>\n      <td>Drug 1288</td>\n      <td>CCN(CC)C(=S)SSC(=S)N(CC)CC</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install networkx==2.8.8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.0+cu118.html --force"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from tdc.single_pred import Tox\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datamol as dm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from evaluation import get_dataloaders, Feed_forward\n",
    "from precompute_3d import precompute_3d\n",
    "\n",
    "df = Tox(name=\"ClinTox\").get_data()\n",
    "mols, smiles = precompute_3d(df[\"Drug\"].to_numpy(), \"ClinTox\")\n",
    "valid_indices = []\n",
    "mols_valid = []\n",
    "i_mol = 0\n",
    "for i,s in enumerate(df[\"Drug\"]):\n",
    "    if dm.to_smiles(dm.to_mol(s), True, False) in smiles and not \"*\" in s:\n",
    "        df[\"Drug\"].iloc[i] = dm.to_smiles(dm.to_mol(s), True, False)\n",
    "        valid_indices.append(i)\n",
    "        mols_valid.append(mols[i_mol])\n",
    "        i_mol += 1\n",
    "\n",
    "df = df.iloc[valid_indices]\n",
    "df[\"Mol\"] = mols_valid\n",
    "\n",
    "smiles = df[\"Drug\"].to_numpy()\n",
    "y = df[\"Y\"].to_numpy()\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "df.sample(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_expe(model_path = \"backbone_pretrained_models/GraphLog/Contextual.pth\", desc_name=\"\", n_epochs = 100, plot=False):\n",
    "    dataloader_train, dataloader_test, input_dim = get_dataloaders(smiles_train, y_train, smiles_test, y_test, desc_name=desc_name, model_path=model_path)\n",
    "    model = Feed_forward(\n",
    "        input_dim = input_dim,\n",
    "        hidden_dim = 128,\n",
    "        output_dim = 1,\n",
    "        n_layers = 1,\n",
    "        d_rate=0.3,\n",
    "        norm=\"batch\"\n",
    "    )\n",
    "    model.train_model(dataloader_train, dataloader_test, n_epochs=n_epochs)\n",
    "    model_name = \"None\" if model_path==\"None\" else model_path.split(\"/\")[-2] + \" \"\n",
    "    if plot:\n",
    "        model.plot_loss(title = model_name + \" \" + desc_name)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "descriptors = [\n",
    "            \"physchem\",\n",
    "            \"ecfp-count\",\n",
    "            \"ecfp\",\n",
    "            \"estate\",\n",
    "            \"erg\",\n",
    "            \"rdkit\",\n",
    "            \"topological\",\n",
    "            \"avalon\",\n",
    "            \"maccs\",\n",
    "            \"scaffoldkeys\",\n",
    "            \"cats\",\n",
    "            \"default\",\n",
    "            \"gobbi\",\n",
    "            \"pmapper\",\n",
    "            \"cats/3D\",\n",
    "            \"gobbi/3D\",\n",
    "            \"pmapper/3D\",\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mi = pd.read_csv(\"resultsClinTox.csv\").groupby([\"X\", \"Y\"])[\"I(X->Y)\"].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "df_desc = {\"descriptor\":[], \"best_acc\": [], \"best_f1\":[], \"best_roc\":[], \"best_aucpr\":[]}\n",
    "\n",
    "N_RUNS = 5\n",
    "p_bar = tqdm(total=len(descriptors) * N_RUNS, desc=\"Fine tuning\",position=0, leave=True)\n",
    "\n",
    "for d in descriptors:\n",
    "        dataloader_train, dataloader_test, input_dim = get_dataloaders(\n",
    "            df_train.Drug, y_train, df_test.Drug, y_test,df_train[\"Mol\"], df_test[\"Mol\"], desc_name=d, model_path=\"None\")\n",
    "        for _ in range(N_RUNS):\n",
    "            df_desc[\"descriptor\"].append(d)\n",
    "            model = Feed_forward(\n",
    "                input_dim = input_dim,\n",
    "                hidden_dim = 128,\n",
    "                output_dim = 1,\n",
    "                n_layers = 1,\n",
    "                d_rate=0.3,\n",
    "                norm=\"batch\"\n",
    "            )\n",
    "            model.train_model(dataloader_train, dataloader_test, n_epochs=300)\n",
    "            best_acc = np.max(model.test_acc)\n",
    "            df_desc[\"best_acc\"].append(best_acc)\n",
    "            df_desc[\"best_f1\"].append(np.max(model.test_f1))\n",
    "            df_desc[\"best_roc\"].append(np.max(model.test_roc))\n",
    "            df_desc[\"best_aucpr\"].append(np.max(model.test_aucpr))\n",
    "            p_bar.update(1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_desc = pd.DataFrame(df_desc)\n",
    "df_desc\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_PATH = \"backbone_pretrained_models\"\n",
    "MODELS = {}\n",
    "# For every directory in the folder\n",
    "for model_name in os.listdir(MODEL_PATH):\n",
    "    # For every file in the directory\n",
    "    for file_name in os.listdir(os.path.join(MODEL_PATH, model_name)):\n",
    "        # If the file is a .pth file\n",
    "        if file_name.endswith(\".pth\"):\n",
    "            MODELS[model_name] = os.path.join(MODEL_PATH, model_name, file_name)\n",
    "MODELS[\"Not-trained\"] = \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "df_model = {\"model\":[], \"best_acc\": [], \"best_f1\":[], \"best_roc\":[], \"best_aucpr\":[]}\n",
    "\n",
    "N_RUNS = 5\n",
    "p_bar = tqdm(total=len(MODELS) * N_RUNS, desc=\"Fine tuning\",position=0, leave=True)\n",
    "\n",
    "for model_name, model_path in MODELS.items():\n",
    "        dataloader_train, dataloader_test, input_dim = get_dataloaders(\n",
    "            df_train.Drug, y_train, df_test.Drug, y_test,df_train[\"Mol\"], df_test[\"Mol\"], desc_name=\"None\", model_path=model_path)\n",
    "        for _ in range(N_RUNS):\n",
    "            df_model[\"model\"].append(model_name)\n",
    "            model = Feed_forward(\n",
    "                input_dim = input_dim,\n",
    "                hidden_dim = 128,\n",
    "                output_dim = 1,\n",
    "                n_layers = 1,\n",
    "                d_rate=0.3,\n",
    "                norm=\"batch\"\n",
    "            )\n",
    "            model.train_model(dataloader_train, dataloader_test, n_epochs=300)\n",
    "            best_acc = np.max(model.test_acc)\n",
    "            df_model[\"best_acc\"].append(best_acc)\n",
    "            df_model[\"best_f1\"].append(np.max(model.test_f1))\n",
    "            df_model[\"best_roc\"].append(np.max(model.test_roc))\n",
    "            df_model[\"best_aucpr\"].append(np.max(model.test_aucpr))\n",
    "            p_bar.update(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(32,16))\n",
    "for i,metric in enumerate([\"best_f1\", \"best_roc\", \"best_aucpr\"]):\n",
    "    sns.barplot(data=df_desc.sort_values(\"best_aucpr\"), x=\"descriptor\", y=metric, hue=\"descriptor\", ax = axes[i])\n",
    "    axes[i].set_ylim(max(0,df_desc[metric].min()-0.05), min(1,df_desc[metric].max() + 0.05))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(df_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(32,16))\n",
    "for i,metric in enumerate([\"best_f1\", \"best_roc\", \"best_aucpr\"]):\n",
    "    sns.barplot(data=df_model.sort_values(\"best_aucpr\"), x=\"model\", y=metric, hue=\"model\", ax = axes[i])\n",
    "    axes[i].set_ylim(max(0,df_desc[metric].min()-0.05), min(1,df_desc[metric].max() + 0.05))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mi = pd.read_csv(\"resultsClinTox.csv\")\n",
    "df_mi[\"I(X->Y)_normed\"] = df_mi.apply(lambda x: x[\"I(X->Y)\"] - df_mi[(df.Y == \"Not-trained\") & (df_mi.X == x.X)][\"I(X->Y)\"].values[0], axis=1)\n",
    "df_mi[\"I(Y->X)_normed\"] = df_mi.apply(lambda x: x[\"I(Y->X)\"] - df_mi[(df.Y == \"Not-trained\") & (df_mi.X == x.X)][\"I(Y->X)\"].values[0], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hue_order = df_model.model.unique()\n",
    "fig, axess = plt.subplots(len(descriptors),3,figsize=(3*7,len(descriptors)*7))\n",
    "first = True\n",
    "for descriptor, axes in zip(descriptors, axess):\n",
    "    df_plot = df_model[~(df_model.model.isin([\"Not-trained\", \"EdgePred\"]))].merge(df_mi, left_on=\"model\", right_on=\"Y\").drop(columns=[\"Y\"]).rename(columns={\"X\":\"descriptor\"})\n",
    "    df_plot = df_plot[df_plot.descriptor == descriptor]\n",
    "    for i,(metric, ax) in enumerate(zip([\"best_f1\", \"best_roc\", \"best_aucpr\"], axes)):\n",
    "        #Scatterplot with linear regression amd corr-coefficient\n",
    "        sns.regplot(data=df_plot, y=metric, x=\"I(X->Y)_normed\", ax =ax, scatter_kws={\"alpha\":0.5}, line_kws={\"color\":\"red\"})\n",
    "        #display correlation coefficient\n",
    "        corr = df_plot[[metric, \"I(X->Y)_normed\"]].corr().iloc[0,1]\n",
    "        ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "        ax.set_title(\"I(X->Y)_normed \" + descriptor + \" \" + str(df_desc[df_desc.descriptor == descriptor][metric].mean())[:4])\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hue_order = df_model.model.unique()\n",
    "fig, axess = plt.subplots(len(descriptors),3,figsize=(3*7,len(descriptors)*7))\n",
    "first = True\n",
    "for descriptor, axes in zip(descriptors, axess):\n",
    "    df_plot = df_model[~(df_model.model.isin([\"Not-trained\", \"EdgePred\"]))].merge(df_mi, left_on=\"model\", right_on=\"Y\").drop(columns=[\"Y\"]).rename(columns={\"X\":\"descriptor\"})\n",
    "    df_plot = df_plot[df_plot.descriptor == descriptor]\n",
    "    for i,(metric, ax) in enumerate(zip([\"best_f1\", \"best_roc\", \"best_aucpr\"], axes)):\n",
    "        #Scatterplot with linear regression amd corr-coefficient\n",
    "        sns.regplot(data=df_plot, y=metric, x=\"I(Y->X)_normed\", ax =ax, scatter_kws={\"alpha\":0.5}, line_kws={\"color\":\"red\"})\n",
    "        #display correlation coefficient\n",
    "        corr = df_plot[[metric, \"I(Y->X)_normed\"]].corr().iloc[0,1]\n",
    "        ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "\n",
    "        ax.set_title(\"I(Y->X)_normed \" +descriptor + \" \" + str(df_desc[df_desc.descriptor == descriptor][metric].mean())[:4])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now also consider a score that aggregates all MIs by suming all normalized MIs weigthed with the descriptor's best performance\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_plot = df_model[~(df_model.model.isin([\"Not-trained\", \"EdgePred\"]))].merge(df_mi, left_on=\"model\", right_on=\"Y\").drop(columns=[\"Y\"]).rename(columns={\"X\":\"descriptor\"})\n",
    "df_tmp_descriptors = df_desc.rename(columns={k: k+\"_desc\" for k in [\"best_f1\", \"best_roc\", \"best_aucpr\"]})\n",
    "df_plot = df_plot.merge(df_tmp_descriptors, left_on=\"descriptor\", right_on=\"descriptor\")\n",
    "df_plot[\"sum_I(X->Y)_item\"] = df_plot[\"I(X->Y)_normed\"] * df_plot[\"best_aucpr_desc\"]\n",
    "df_plot[\"sum_I(Y->X)_item\"] = df_plot[\"I(Y->X)_normed\"] * df_plot[\"best_aucpr_desc\"]\n",
    "\n",
    "sum_values = df_plot.groupby(\"model\")[[\"sum_I(X->Y)_item\", \"sum_I(Y->X)_item\"]].sum().reset_index().rename(columns={\"sum_I(X->Y)_item\":\"sum_I(X->Y)\", \"sum_I(Y->X)_item\":\"sum_I(Y->X)\"})\n",
    "\n",
    "df_plot = df_plot.merge(sum_values, left_on=\"model\", right_on=\"model\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(20, 5), sharex=True)\n",
    "for i, (ax, metric) in enumerate(zip(axes, [\"best_f1\", \"best_roc\", \"best_aucpr\"])):\n",
    "    sns.scatterplot(data=df_plot, y=metric, x=\"sum_I(X->Y)\", hue=\"model\", palette=\"Set3\", alpha=0.5, ax=ax, legend=i==0)\n",
    "    #corr coefficient\n",
    "    corr = df_plot[[metric, \"sum_I(X->Y)\"]].corr().iloc[0,1]\n",
    "    ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(metric.split(\"_\")[1])\n",
    "\n",
    "axes[1].set_xlabel(\n",
    "    \"$\\sum_{desc\\in descriptors} [\\mathcal{I} ( desc->model ) - \\mathcal{I}(desc->model_{NT})$] metric$(desc)$\"\n",
    ")\n",
    "\n",
    "fig.suptitle(\"$\\mathcal{I} ( desc->model )$ score's correlation to the best performance of each evaluated model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(20, 5), sharex=True)\n",
    "for i, (ax, metric) in enumerate(zip(axes, [\"best_f1\", \"best_roc\", \"best_aucpr\"])):\n",
    "    sns.scatterplot(data=df_plot, y=metric, x=\"sum_I(Y->X)\", hue=\"model\", palette=\"Set3\", alpha=0.5, ax=ax, legend=i==0)\n",
    "    #corr coefficient\n",
    "    corr = df_plot[[metric, \"sum_I(Y->X)\"]].corr().iloc[0,1]\n",
    "    ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(metric.split(\"_\")[1])\n",
    "\n",
    "axes[1].set_xlabel(\n",
    "    \"$\\sum_{desc\\in descriptors} [\\mathcal{I} ( model-> desc) - \\mathcal{I}(model_{NT} -> desc)$] metric$(desc)$\"\n",
    ")\n",
    "\n",
    "fig.suptitle(\"$\\mathcal{I} ( model-> desc)$ score's correlation to the best performance of each evaluated model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_plot[\"compression\"] = df_plot[\"sum_I(Y->X)\"] - df_plot[\"sum_I(X->Y)\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(20, 5), sharex=True)\n",
    "for i, (ax, metric) in enumerate(zip(axes, [\"best_f1\", \"best_roc\", \"best_aucpr\"])):\n",
    "    sns.scatterplot(data=df_plot, y=metric, x=\"compression\", hue=\"model\", palette=\"Set3\", alpha=0.5, ax=ax, legend=i==0)\n",
    "    #corr coefficient\n",
    "    corr = df_plot[[metric, \"compression\"]].corr().iloc[0,1]\n",
    "    ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(metric.split(\"_\")[1])\n",
    "\n",
    "axes[1].set_xlabel(\n",
    "    \"$\\sum_{desc\\in descriptors} [\\mathcal{I} ( model-> desc) - \\mathcal{I}(model_{NT} -> desc)$] metric$(desc)$\"\n",
    ")\n",
    "\n",
    "fig.suptitle(\"$\\mathcal{I} ( model-> desc)$ score's correlation to the best performance of each evaluated model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_plot[\"compression_dummy\"] = (df_plot[\"sum_I(X->Y)\"] - df_plot[\"sum_I(X->Y)\"].max())/(df_plot[\"sum_I(X->Y)\"].min() - df_plot[\"sum_I(X->Y)\"].max()) - (df_plot[\"sum_I(Y->X)\"] - df_plot[\"sum_I(Y->X)\"].max())/(df_plot[\"sum_I(Y->X)\"].min() - df_plot[\"sum_I(Y->X)\"].max())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(20, 5), sharex=True)\n",
    "for i, (ax, metric) in enumerate(zip(axes, [\"best_f1\", \"best_roc\", \"best_aucpr\"])):\n",
    "    sns.scatterplot(data=df_plot, y=metric, x=\"compression_dummy\", hue=\"model\", palette=\"Set3\", alpha=0.5, ax=ax, legend=i==0)\n",
    "    #corr coefficient\n",
    "    corr = df_plot[[metric, \"compression_dummy\"]].corr().iloc[0,1]\n",
    "    ax.text(0.05, 0.95, \"corr: \" + str(corr)[:4], transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(metric.split(\"_\")[1])\n",
    "\n",
    "axes[1].set_xlabel(\n",
    "    \"Weird compression stuff\"\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Really weird compression stuff\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import ZINC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = ZINC(root='/tmp/ZINC', subset=True, split='val')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tdc_dataset import get_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_dataset(dataset: str):\n",
    "    try:\n",
    "        df = correspondancy_dict[dataset](name=dataset).get_data()\n",
    "    except:\n",
    "        label_list = retrieve_label_name_list(dataset)\n",
    "        df = correspondancy_dict[dataset](name=dataset, label_name=label_list[0]).get_data()\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = get_dataset(\"QM7b\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
