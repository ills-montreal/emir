{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from visu_utils import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94413dde18d560b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SUBSET_NAME = \"comprehensive\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e0296e041e76da5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef97a974aefd1e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_base = pd.read_csv('../../output/comprehensive_2/base.csv')\n",
    "df_mis = pd.read_csv('../../output/comprehensive_2/mis.csv')\n",
    "df_rouge = pd.read_csv('../../output/comprehensive_2/rouge.csv')\n",
    "\n",
    "df_classifiers = pd.read_csv('../../output/comprehensive_3/classifiers.csv')\n",
    "model_sizes = pd.read_csv('../../output/model_sizes.csv')\n",
    "\n",
    "df_bert = pd.read_csv('../../output/comprehensive_2/bert.csv')\n",
    "df_bart = pd.read_csv('../../output/comprehensive_2/bart.csv')\n",
    "df_emb = pd.read_csv('../../output/comprehensive_2/emb.csv')\n",
    "\n",
    "\n",
    "df_base['source'] = df_base[\"Unnamed: 0\"]\n",
    "df_rouge['source'] = df_rouge[\"Unnamed: 0\"]\n",
    "df_classifiers['source'] = df_classifiers[\"Unnamed: 0\"]\n",
    "df_mis['source'] = df_mis[\"filename\"]\n",
    "df_bert['source'] = df_bert[\"Unnamed: 0\"]\n",
    "df_emb['source'] = df_emb[\"Unnamed: 0\"]\n",
    "df_bart['source'] = df_bart[\"Unnamed: 0\"]\n",
    "\n",
    "\n",
    "# drop I(text -> summary) and I(summary -> text), H(text) and H(summary) and H(text|summary), H(summary|text) from df_base\n",
    "df_base = df_base.drop(\n",
    "    columns=['I(text -> summary)', 'I(summary -> text)', 'H(text)', 'H(summary)', 'H(text|summary)', 'H(summary|text)',\n",
    "             'metadata/Embedding model'])\n",
    "\n",
    "# merge all dataframes on source\n",
    "df_comprehensive = df_base.merge(df_rouge, on='source', how=\"outer\")\n",
    "df_comprehensive = df_comprehensive.merge(df_classifiers, on='source')\n",
    "# merge emb and bert\n",
    "df_comprehensive = df_comprehensive.merge(df_bert, on='source')\n",
    "df_comprehensive = df_comprehensive.merge(df_bart, on='source')\n",
    "df_comprehensive = df_comprehensive.merge(df_emb, on='source')\n",
    "\n",
    "df_comprehensive = df_comprehensive.merge(df_mis[['source', 'I(summary -> text)', 'I(text -> summary)', 'H(text)',\n",
    "                                                  'H(summary)', 'H(text|summary)', 'H(summary|text)',\n",
    "                                                  'metadata/Embedding model']], on='source')\n",
    "\n",
    "\n",
    "df_comprehensive['metadata/Model name'] = df_comprehensive['source'].apply(lambda x: x.split('-_-')[0])\n",
    "df_comprehensive['metadata/Decoding config'] = df_comprehensive['source'].apply(lambda x: x.split('-_-')[2])\n",
    "df_comprehensive['metadata/Dataset name'] = df_comprehensive['source'].apply(lambda x: x.split('-_-')[1])\n",
    "\n",
    "\n",
    "# remove all columns with gold\n",
    "df_comprehensive = df_comprehensive[[c for c in df_comprehensive.columns if \"gold\" not in c]]\n",
    "\n",
    "\n",
    "df_comprehensive = df_comprehensive.merge(model_sizes, on='metadata/Model name')\n",
    "\n",
    "# replace first _ in model by /\n",
    "df_comprehensive['metadata/Model name'] = df_comprehensive['metadata/Model name'].apply(\n",
    "    lambda x: x.replace('_', '/', 1))\n",
    "\n",
    "\n",
    "# get all pair of columns with _x, _y\n",
    "def get_pair_columns(df):\n",
    "    cols = df.columns\n",
    "    pairs = []\n",
    "    for c in cols:\n",
    "        if c.endswith(\"_x\"):\n",
    "            pairs.append((c, c.replace(\"_x\", \"_y\")))\n",
    "    return pairs\n",
    "\n",
    "# add column without suffix _x or _y, getting the non nan value or the _x value if both are not nan\n",
    "def add_column(df, col1, col2):\n",
    "    df[col1.replace(\"_x\", \"\")] = df.apply(lambda x: x[col1] if pd.isna(x[col2]) else x[col2], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# remove all unamed columns\n",
    "df_comprehensive = df_comprehensive[[c for c in df_comprehensive.columns if \"Unnamed\" not in c]]\n",
    "\n",
    "# add columns\n",
    "for col1, col2 in get_pair_columns(df_comprehensive):\n",
    "    df_comprehensive = add_column(df_comprehensive, col1, col2)\n",
    "    \n",
    "# drop columns with _x or _y\n",
    "df_comprehensive = df_comprehensive[[c for c in df_comprehensive.columns if not c.endswith(\"_x\") and not c.endswith(\"_y\")]]\n",
    "\n",
    "\n",
    "EMBEDDER_NAME = df_comprehensive['metadata/Embedding model'].unique()[0].replace('/', '_')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_no_arxiv = df_comprehensive[~df_comprehensive['metadata/Model name'].str.contains('arxiv')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7283675c67a0455"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_comprehensive.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4af84d7906749ec7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print all model names:\n",
    "\n",
    "\n",
    "# ['google/pegasus-arxiv' 'sshleifer/distill-pegasus-cnn-16-4'\n",
    "#  'sshleifer/distilbart-cnn-12-6' 'Falconsai/medical_summarization'\n",
    "#  'airKlizz/mt5-base-wikinewssum-all-languages'\n",
    "#  'sshleifer/distilbart-xsum-12-1' 'google/pegasus-large'\n",
    "#  'facebook/bart-large-cnn' 'sshleifer/distilbart-cnn-6-6'\n",
    "#  'sshleifer/distilbart-cnn-12-3' 'sshleifer/distill-pegasus-xsum-16-4'\n",
    "#  'google/pegasus-multi_news' 'sshleifer/distilbart-xsum-6-6'\n",
    "#  'Falconsai/text_summarization']\n",
    "\n",
    "# Make a column that records if XSUM/CNN Daily Mail are IN or OOD\n",
    "\n",
    "is_ood_map = {'google/pegasus-arxiv': 'OOD', 'sshleifer/distill-pegasus-cnn-16-4': 'IN',\n",
    "              'sshleifer/distilbart-cnn-12-6': 'IN', 'Falconsai/medical_summarization': 'OOD',\n",
    "              'airKlizz/mt5-base-wikinewssum-all-languages': 'IN', 'sshleifer/distilbart-xsum-12-1': 'IN',\n",
    "              'google/pegasus-large': 'IN', 'facebook/bart-large-cnn': 'IN',\n",
    "              'sshleifer/distilbart-cnn-12-3': 'IN',\n",
    "              'sshleifer/distill-pegasus-xsum-16-4': 'IN', 'google/pegasus-multi_news': 'IN',\n",
    "              'sshleifer/distilbart-xsum-6-6': 'IN', 'Falconsai/text_summarization': 'IN',\n",
    "              'sshleifer/distilbart-cnn-12-1': 'IN', 'sshleifer/distilbart-cnn-6-3': 'IN',\n",
    "              'sshleifer/distilbart-cnn-6-1': 'IN', 'sshleifer/distilbart-cnn-12-12': 'IN',\n",
    "              'sshleifer/distilbart-cnn-12-9': 'IN', 'sshleifer/distilbart-cnn-12-1': 'IN',\n",
    "              'sshleifer/distilbart-cnn-6-6': 'IN', 'sshleifer/distilbart-cnn-12-3': 'IN',\n",
    "              \"mistralai/Mistral-7B-Instruct-v0.2\" : \"IN\",\n",
    "              }\n",
    "\n",
    "df_comprehensive['metadata/IND/OOD'] = df_comprehensive['metadata/Model name'].apply(lambda x: is_ood_map[x])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b9dcaaed32ad0c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bbfa38749d07828c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model summary table"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c01f9c965297366"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f611943c9aeb1c6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "table = make_table_model_summary(df_comprehensive)\n",
    "\n",
    "style = table.style\n",
    "\n",
    "style = style.format(precision=2)\n",
    "style = style.format_index(escape=\"latex\", axis=0)\n",
    "\n",
    "# add background gradient\n",
    "\n",
    "# convert to latex\n",
    "path = f\"../../../papers/Mutual-information-for-summarization/tables/{SUBSET_NAME}_{EMBEDDER_NAME}_model_summaries_table.tex\"\n",
    "# create parent\n",
    "Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "latex_code = style.to_latex(clines=\"skip-last;data\", sparse_index=True, sparse_columns=True,\n",
    "                            caption=\"Summary of the models we benchmarked with their name on the Huggingface hub, size and performance metrics.\",\n",
    "                            label=\"tab:model_summaries\", environment=\"table*\", hrules=True, convert_css=True)\n",
    "\n",
    "import re\n",
    "\n",
    "# add a resize box around the tabular\n",
    "latex_code = re.sub(r\"\\\\begin{tabular}\", r\"\\\\resizebox{\\\\textwidth}{!}{\\\\begin{tabular}\", latex_code)\n",
    "latex_code = re.sub(r\"\\\\end{tabular}\", r\"\\\\end{tabular}}\", latex_code)\n",
    "\n",
    "# add centering to the table environment\n",
    "latex_code = re.sub(r\"\\\\begin{table\\*}\", r\"\\\\begin{table*}[h!]\\\\centering\", latex_code)\n",
    "\n",
    "# save latex code\n",
    "with open(path, 'w') as f:\n",
    "    f.write(latex_code)\n",
    "    \n",
    "display(style)\n",
    "\n",
    "# table = table[['$I(T,S)$', '\\\\texttt{ROUGE-L}', '\\\\texttt{BERTScore}', '\\\\texttt{BARTScore}', 'M. I.', 'Attr.', 'Conc.']]\n",
    "# table = table.rename(columns={'\\\\texttt{ROUGE-L}': 'ROUGE-L', '\\\\texttt{BERTScore}': 'BERTScore', '\\\\texttt{BARTScore}': 'BARTScore', 'M. I.': 'Main ideas', 'Attr.': 'Attribution', 'Conc.': 'Conciseness'})\n",
    "# \n",
    "# table = table.groupby(level=0, axis=0).mean().melt(var_name='metric', value_name='value', ignore_index=False)\n",
    "# table[\"ones\"] = 1\n",
    "# table = table.reset_index()\n",
    "# \n",
    "# # make ranking of Model by metric\n",
    "# \n",
    "# # Rank model by metric\n",
    "# table['rank'] = 1 + table.sort_values(['metric', 'value'], ascending=False).groupby('metric').cumcount()\n",
    "# table\n",
    "# \n",
    "# fig, ax = plt.subplots(1, 1, figsize=(40, 35))\n",
    "# marker = ['o', 's', 'D', 'v', '^', '<', '>', 'p', 'h', 'H', 'd', 'P', 'X', '*', '8', '1', '2', '3', '4', 'x', '|', '_', '']\n",
    "# line_params = {'linewidth': 10, 'alpha': 0.5, 'markersize': 20}\n",
    "# sns.pointplot(data=table.reset_index(), x='metric', y='rank', hue='Model', ax=ax, linewidth=30, palette='tab20', alpha=0.8, markers=marker, markersize=20)\n",
    "# \n",
    "# ax.set_xlabel(\"Metric\", fontsize=50, fontweight='bold')\n",
    "# ax.set_ylabel(\"Rank\", fontsize=50, fontweight='bold')\n",
    "# \n",
    "# ax.tick_params(axis='x', labelsize=50, rotation=30, labelfontfamily='monospace')\n",
    "# ax.tick_params(axis='y', labelsize=50)\n",
    "# \n",
    "# # legend fontsize\n",
    "# # legend outside below\n",
    "# ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.20), ncol=2, fontsize=50)\n",
    "# \n",
    "# # add grid\n",
    "# ax.grid(True, which='both', axis='both', linestyle='solid')\n",
    "# \n",
    "# path = f\"../../../papers/Mutual-information-for-summarization/img/{SUBSET_NAME}_{EMBEDDER_NAME}_model_summaries_ranking.png\"\n",
    "# # create parent\n",
    "# Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "# \n",
    "# fig.tight_layout()\n",
    "# plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755bab1b69b02bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d769f537ff4f2f94",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a6b58e63420ba4f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3e0062e1fd6958f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "999a008a63ce4ec9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_no_arxiv['H'] = df_no_arxiv[['H(text|summary)', 'H(summary|text)']].mean(axis=1)\n",
    "table = make_correlation_table(df_no_arxiv).transpose()\n",
    "\n",
    "# take average over the first level of columns\n",
    "\n",
    "table = table.groupby(level=1, axis=1).mean()\n",
    "\n",
    "\n",
    "display(table)\n",
    "\n",
    "\n",
    "# table.columns = pd.MultiIndex.from_tuples([(c[0].replace('_', '-'), c[1]) for c in table.columns])\n",
    "\n",
    "style = table.style\n",
    "\n",
    "style = style.format(precision=2)\n",
    "# style = style.format_index(escape=\"latex\", axis=0)\n",
    "\n",
    "# highlight max for each dataset with bfseries\n",
    "# list_datasets = set(table.columns.get_level_values(0))\n",
    "#list_metrics = set(table.columns.get_level_values(1))\n",
    "idx = pd.IndexSlice\n",
    "# for dataset in list_datasets:\n",
    "#    style = style.highlight_max(axis=1, subset=(idx[:], idx[dataset, :]), props='bfseries:')\n",
    "\n",
    "# add background gradient\n",
    "style = style.background_gradient(cmap='viridis', vmin=0.2, vmax=1)\n",
    "\n",
    "# convert to latex\n",
    "path = f\"../../../papers/Mutual-information-for-summarization/tables/{SUBSET_NAME}_{EMBEDDER_NAME}_correlation_table_full.tex\"\n",
    "# create parent\n",
    "Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "latex_code = style.to_latex(clines=\"skip-last;data\", sparse_index=True, sparse_columns=True,\n",
    "                            caption=\"Correlation between MI and ROUGE, and Seahorse metrics and probability of success of the classifcation task, grouped by datasets for non-trivial decoding strategies. SH. stands for Seahorse metrics and CT. for classification tasks.\",\n",
    "                            label=\"tab:correlation_table\", environment=\"table\", hrules=True, convert_css=True, multicol_align=\"c\")\n",
    "\n",
    "import re\n",
    "\n",
    "# add a resize box around the tabular\n",
    "latex_code = re.sub(r\"\\\\begin{tabular}\", r\"\\\\resizebox{0.5\\\\textwidth}{!}{\\\\begin{tabular}\", latex_code)\n",
    "latex_code = re.sub(r\"\\\\end{tabular}\", r\"\\\\end{tabular}}\", latex_code)\n",
    "\n",
    "# add centering to the table environment\n",
    "latex_code = re.sub(r\"\\\\begin{table}\", r\"\\\\begin{table}\\\\centering\", latex_code)\n",
    "\n",
    "# save latex code\n",
    "with open(path, 'w') as f:\n",
    "    f.write(latex_code)\n",
    "    \n",
    "\n",
    "print(latex_code)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0bb61b3451a84c2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "table = make_correlation_table(df_no_arxiv)\n",
    "\n",
    "table = table.groupby(level=1, axis=0).mean()\n",
    "table_sh = table['SH.']\n",
    "\n",
    "# drop Main ideas and Attribution rows\n",
    "table_sh = table_sh.drop(index=['Main ideas', 'Attribution'])\n",
    "\n",
    "style = table_sh.style\n",
    "\n",
    "style = style.format(precision=2)\n",
    "\n",
    "# export to latex\n",
    "path = f\"../../../papers/Mutual-information-for-summarization/tables/{SUBSET_NAME}_{EMBEDDER_NAME}_correlation_table_sh.tex\"\n",
    "\n",
    "# create parent\n",
    "Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "latex_code = style.to_latex(clines=\"skip-last;data\", sparse_index=True, sparse_columns=True,\n",
    "                            caption=\"Common quality estimation metrics correlation with human judgement estimated by Seahorse metrics.\",\n",
    "                            label=\"tab:correlation_table_sh\", environment=\"table\", hrules=True, convert_css=True, multicol_align=\"c\")\n",
    "\n",
    "latex_code = re.sub(r\"\\\\begin{tabular}\", r\"\\\\resizebox{0.5\\\\textwidth}{!}{\\\\begin{tabular}\", latex_code)\n",
    "latex_code = re.sub(r\"\\\\end{tabular}\", r\"\\\\end{tabular}}\", latex_code)\n",
    "\n",
    "# add centering to the table environment\n",
    "latex_code = re.sub(r\"\\\\begin{table}\", r\"\\\\begin{table}\\\\centering\", latex_code)\n",
    "\n",
    "shorten_map = {\"Conciseness\": \"Conc.\", \"Main ideas\": \"M. Ideas\", \"Attribution\": \"Attr.\", \"Grammar\": \"Gram.\", \"Comprehensible\": \"Compr.\", \"Concise\": \"Cons.\"}\n",
    "\n",
    "for k, v in shorten_map.items():\n",
    "    latex_code = latex_code.replace(k, v)\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    f.write(latex_code)\n",
    "    \n",
    "display(style)\n",
    "\n",
    "# remove latex commands from metric names\n",
    "def remove_latex(x):\n",
    "    # get everything between { and }\n",
    "    matches = re.findall(r\"\\{(.*)\\}\", x)\n",
    "    if len(matches) > 0:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "table_sh = table_sh.rename(index=remove_latex)\n",
    "\n",
    "# melt table\n",
    "table_sh = table_sh.reset_index()\n",
    "print(table_sh.columns)\n",
    "table_sh = table_sh.melt(var_name='metric', value_name='correlation', id_vars=['Metric'])\n",
    "\n",
    "# barplot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "# barplot with annotations\n",
    "sns.barplot(data=table_sh, x='metric', y='correlation', hue='Metric', ax=ax, palette='tab10')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='\\n%.1f', label_type='center', fontsize=14)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Correlation\", fontsize=20, fontweight='bold')\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=25, rotation=45, labelfontfamily='monospace')\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "# legend fontsize\n",
    "ax.legend(fontsize=20)\n",
    "\n",
    "path = f\"../../../papers/Mutual-information-for-summarization/img/{SUBSET_NAME}_correlation_table_sh.png\"\n",
    "# create parent\n",
    "Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ff9f68e0bda405"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "table = make_correlation_table(df_no_arxiv)\n",
    "\n",
    "table = table.groupby(level=1, axis=0).mean()\n",
    "\n",
    "table_sh = pd.concat([table['CT.'], table['Emb.']], axis=1)\n",
    "\n",
    "# columns short names\n",
    "shorten_map = {\"Sentiment analysis\": \"Sent. analysis\", \"GPT detector\": \"GPT det.\", \"Topic classification\": \"Topic.\", \"Policy classification\": \"Policy\", \"Emotion classification\": \"Emotion\", \"Emb. Paraphrase\": \"Emb.\"}\n",
    "\n",
    "table_sh = table_sh.rename(columns=shorten_map)\n",
    "\n",
    "style = table_sh.style\n",
    "\n",
    "style = style.format(precision=2)\n",
    "\n",
    "path = f\"../../../papers/Mutual-information-for-summarization/tables/{SUBSET_NAME}_{EMBEDDER_NAME}_correlation_table_ct.tex\"\n",
    "\n",
    "# create parent\n",
    "Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "latex_code = style.to_latex(clines=\"skip-last;data\", sparse_index=True, sparse_columns=True,\n",
    "                            caption=\"Common quality estimation metrics correlation with the performance on the downstream classification tasks. Where Sent. analysis stands for sentiment analysis, GPT det. for GPT detector, Topic. for topic classification, Policy for policy classification, Emotion for emotion classification and Emb. for paraphrase embedding.\",\n",
    "                            label=\"tab:correlation_table_ct\", environment=\"table\", hrules=True, convert_css=True, multicol_align=\"c\")\n",
    "\n",
    "latex_code = re.sub(r\"\\\\begin{tabular}\", r\"\\\\resizebox{0.5\\\\textwidth}{!}{\\\\begin{tabular}\", latex_code)\n",
    "latex_code = re.sub(r\"\\\\end{tabular}\", r\"\\\\end{tabular}}\", latex_code)\n",
    "\n",
    "# add centering to the table environment\n",
    "latex_code = re.sub(r\"\\\\begin{table}\", r\"\\\\begin{table}\\\\centering\", latex_code)\n",
    "\n",
    "\n",
    "    \n",
    "with open(path, 'w') as f:\n",
    "    f.write(latex_code)\n",
    "    \n",
    "display(style)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8021c2502e507c76",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "\n",
    "# radar chart function\n",
    "\n",
    "def make_radar_chart(df, indexes, columns, ax, ylim, yticks, legend):\n",
    "    df = df.copy()\n",
    "\n",
    "    # retrieve data\n",
    "    data = df.loc[indexes, columns]\n",
    "    \n",
    "    # data = data.sort_index(axis=1)\n",
    "    \n",
    "    # make a plot for each row\n",
    "\n",
    "\n",
    "    # to 0 if negative\n",
    "    # values = np.array([0.01 if v < 0 else v for v in values])\n",
    "    # get columns\n",
    "    b_angles = [n / float(len(columns)) * 2 * math.pi for n in range(len(columns))]\n",
    "    \n",
    "    angles = b_angles + b_angles[:1]\n",
    "    b_angles = b_angles + b_angles[:1]\n",
    "\n",
    "    # dic with angle for each column\n",
    "    angles_dict = {c: a for c, a in zip(columns, b_angles)}\n",
    "\n",
    "\n",
    "    color_list = ['tab:green', 'tab:orange', 'tab:blue', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink',\n",
    "              'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "    \n",
    "    category_color_list = ['cornflowerblue', 'indianred', 'lightgreen', 'lightcoral', 'lightpink', 'lightgrey', 'lightyellow', 'lightcyan', 'lightseagreen']\n",
    "    category_hat_list = ['/', '\\\\', '|', '-', '+', 'x', 'o', 'O', '.']\n",
    "    \n",
    "    last_angle = 0\n",
    "    for k, level_0 in enumerate(data.columns.get_level_values(0).unique()):\n",
    "        print(level_0)\n",
    "        print(data[level_0].columns)\n",
    "        \n",
    "        start_angle =  angles_dict[(level_0, data[level_0].columns[0])] \n",
    "        end_angle = angles_dict[(level_0, data[level_0].columns[-1])]\n",
    "\n",
    "        if start_angle > end_angle:\n",
    "            start_angle, end_angle = end_angle, start_angle\n",
    "\n",
    "        start_angle = start_angle - 1/(float(len(columns))) * math.pi\n",
    "        \n",
    "        # if k == len(data.columns.get_level_values(0).unique()) - 1:\n",
    "        #     end_angle = 2 * math.pi - 1/(float(len(columns))) * math.pi\n",
    "        # else:\n",
    "        end_angle = end_angle + 1/(float(len(columns))) * math.pi\n",
    "            \n",
    "        langles = np.arange(start_angle, end_angle, 0.01)\n",
    "\n",
    "        ax.fill_between(langles,  0.9*np.ones(len(langles)), 1.2*np.ones(len(langles)), alpha=0.6, color=category_color_list[k], label=level_0, hatch=category_hat_list[k])\n",
    "\n",
    "    \n",
    "    for k, (idx, row) in enumerate(data.iterrows()):\n",
    "        # get values\n",
    "        values = row.values\n",
    "        values = np.concatenate((values, [values[0]]))\n",
    "        \n",
    "        # plot\n",
    "        if \"ROUGE\" in idx:\n",
    "            idx = \"ROUGE-L\"\n",
    "        elif \"BERT\" in idx:\n",
    "            idx = \"BERTScore\"\n",
    "        elif \"BART\" in idx:\n",
    "            idx = \"BARTScore\"\n",
    "\n",
    "        linestyles = ['dotted', 'dashed', 'dashdot', 'looosely dashed', 'densely dashed', 'loosely dotted', 'densely dotted', 'loosely dashdotted', 'densely dashdotted', 'loosely dashdotdotted', 'densely dashdotdotted']\n",
    "        # fill\n",
    "        if \"I(S;T)\" in idx:\n",
    "            ax.plot(angles, values, linewidth=5, linestyle='solid', label=idx, color=color_list[k])\n",
    "            ax.fill(angles, values, alpha=0.1, color=color_list[k])\n",
    "        else:\n",
    "            ax.plot(angles, values, linewidth=3, linestyle='--', label=idx, color=color_list[k])\n",
    "            ax.fill(angles, values, alpha=0.1, color=color_list[k])\n",
    "\n",
    "        # add legend\n",
    "\n",
    "        # add grid\n",
    "    ax.grid(True, which='both', axis='both', linestyle='solid')\n",
    "    \n",
    "\n",
    "    # set xticks\n",
    "    ax.set_xticks(angles[:-1])\n",
    "\n",
    "    # set xtick labels\n",
    "    cc = []\n",
    "    for c in columns:\n",
    "        if \"ROUGE\" in c[1]:\n",
    "            cc.append(\"ROUGE-L\")\n",
    "        elif \"BERT\" in c[1]:\n",
    "            cc.append(\"BERTScore\")\n",
    "        elif \"BART\" in c[1]:\n",
    "            cc.append(\"BARTScore\")\n",
    "\n",
    "        else:\n",
    "            cc.append(c[1])\n",
    "    ax.set_xticklabels(cc, fontsize=20, fontweight='bold')\n",
    "    \n",
    "\n",
    "    # set yticks\n",
    "    ax.set_yticks(yticks)\n",
    "\n",
    "    # set ytick labels\n",
    "    ax.set_yticklabels(yticks, fontsize=16)\n",
    "\n",
    "    # set ylim\n",
    "    ax.set_ylim(ylim)\n",
    "        \n",
    "        \n",
    "# draw a circle at y=0\n",
    "    ax.plot(np.linspace(0, 2 * math.pi, 100), np.zeros(100), linestyle='--', color='black', linewidth=2, label=\"Correlation = 0\")\n",
    "    \n",
    "    ax.set_axisbelow(False)\n",
    "\n",
    "table = make_correlation_table(df_no_arxiv).transpose()\n",
    "\n",
    "datasets = ['xsum', 'cnn_dailymail', 'multi_news']\n",
    "\n",
    "dddf = table['xsum'].transpose()\n",
    "\n",
    "columns = [c for c in dddf.columns]\n",
    "\n",
    "fig, ax = plt.subplots(1, len(datasets), figsize=(30, 25), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "\n",
    "\n",
    "for k, d in enumerate(datasets):\n",
    "    dddf = table[d].transpose()\n",
    "    make_radar_chart(df=dddf, indexes=dddf.index, columns=columns, ax=ax[k], ylim=(-0.6, 1.1), yticks=[-0.6, -0.2, 0.2, 0.6, 1.0], legend=False)\n",
    "    \n",
    "    if d == \"cnn_dailymail\":\n",
    "        # ax[k].legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3, fontsize=20)\n",
    "        handles, labels = ax[k].get_legend_handles_labels()\n",
    "    else:\n",
    "        ax[k].legend().remove()\n",
    "    \n",
    "    ax[k].set_title(d, fontsize=22, fontweight='bold')\n",
    "    \n",
    "# make global legend\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, 0.1), ncol=3, fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"../../../papers/Mutual-information-for-summarization/img/{SUBSET_NAME}_{EMBEDDER_NAME}_radar_chart_all.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "# columns = [c for c in dddf.columns if \"SH.\" in c]\n",
    "# \n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "# make_radar_chart(df=dddf, indexes=dddf.index, columns=columns, ax=ax, ylim=(-1, 1), yticks=[-1, -0.6, -0.2, 0.2, 0.6, 1.0])\n",
    "# \n",
    "# \n",
    "# columns = [c for c in dddf.columns if \"CT.\" in c]\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "# make_radar_chart(df=dddf, indexes=dddf.index, columns=columns, ax=ax, ylim=(0, 1), yticks=[0.2, 0.6, 0.8, 1.0]) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eafb612f7fd506b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e0c8f104897af",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "ROUGES = [\"common/rougeLsum\"]\n",
    "MI = ['I(summary -> text)', 'I(text -> summary)', 'max mi', 'min mi']\n",
    "SHM = [c for c in df_comprehensive.columns if \"SHMetric\" in c and \"proba_1\" in c]\n",
    "# keep only Attribution, Main idea, Conciseness\n",
    "SHM = [c for c in SHM if \"Attribution\" in c or \"Main ideas\" in c or \"Conciseness\" in c]\n",
    "\n",
    "map_tasks = {\"mrm8488_distilroberta-finetuned-financial-news-sentiment-analysis\": \"Sentiment analysis\",\n",
    "             \"roberta-base-openai-detector\": \"GPT detector\",\n",
    "             \"manifesto-project_manifestoberta-xlm-roberta-56policy-topics-context-2023-1-1\" : \"Topic classification\",\n",
    "             }\n",
    "\n",
    "classification_tasks_error = [c + \"/proba_of_error\" for c in map_tasks.keys()]\n",
    "classification_tasks = [c + \"/proba_of_success\" for c in map_tasks.keys()]\n",
    "\n",
    "# make proba_of_error proba_of_success\n",
    "df_comprehensive[classification_tasks] = 1 - df_comprehensive[classification_tasks_error]\n",
    "\n",
    "\n",
    "def plot_multiple_datasets_correlations(df, COLS, metric, name):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df[~df['metadata/Decoding config'].str.contains(\"short\")]\n",
    "\n",
    "    df = df[~df['metadata/Decoding config'].isin([f\"beam_sampling_{k}\" for k in [5, 10, 20, 50]])]\n",
    "\n",
    "    datasets = set(df['metadata/Dataset name'].dropna().unique())\n",
    "    datasets -= set(['peer_read', 'arxiv', 'rotten_tomatoes'])\n",
    "\n",
    "    fig, axes = plt.subplots(len(datasets), len(COLS), figsize=(10, 10), sharey=False, sharex=False, dpi=300)\n",
    "\n",
    "    def rename_cols(x):\n",
    "        if \"SHMetric\" in x:\n",
    "            return x.split('/')[1]\n",
    "        else:\n",
    "            return map_tasks[x.split('/')[0]]\n",
    "\n",
    "    for idx, col in enumerate(COLS):\n",
    "        for didx, ds in enumerate(datasets):\n",
    "            group = df[df['metadata/Dataset name'] == ds]\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "            sns.regplot(data=group, x=metric, y=col, ax=axes[didx, idx], x_ci=None, ci=False, scatter=False,\n",
    "                        line_kws={'alpha': 0.5, 'linewidth': 5})\n",
    "            sns.scatterplot(data=group, x=metric, y=col, hue='metadata/Model name', style='metadata/Model name',\n",
    "                            ax=axes[didx, idx], palette='tab20', s=300)\n",
    "\n",
    "            axes[didx, idx].set_xlabel(\"\")\n",
    "            if didx == 0:\n",
    "                axes[didx, idx].set_title(rename_cols(col), fontsize=22, fontweight='bold')\n",
    "\n",
    "            axes[didx, idx].set_ylabel(\"\")\n",
    "            if idx == 0:\n",
    "                axes[didx, idx].set_ylabel(ds, fontsize=22, fontweight='bold')\n",
    "\n",
    "            # make xtick labels bigger\n",
    "            axes[didx, idx].tick_params(axis='x', labelsize=18)\n",
    "            axes[didx, idx].tick_params(axis='y', labelsize=18)\n",
    "\n",
    "            # add grid\n",
    "            axes[didx, idx].grid(True, which='both', axis='both', linestyle='--')\n",
    "\n",
    "    # global legend below the figure\n",
    "    handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.22), ncol=2, fontsize=14)\n",
    "    # remove all legends\n",
    "    for ax in axes.flatten():\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "    path = f\"../../../papers/Mutual-information-for-summarization/img/{SUBSET_NAME}_{EMBEDDER_NAME}_multiple_datasets_correlations_{name}.png\"\n",
    "    # create parent\n",
    "\n",
    "    fig.tight_layout()\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plot_multiple_datasets_correlations(df_comprehensive, COLS=SHM, metric=\"I(summary -> text)\", name=\"shmetrics_full_mi\")\n",
    "plot_multiple_datasets_correlations(df_comprehensive, COLS=classification_tasks, metric=\"I(summary -> text)\",\n",
    "                                   name=\"classification_tasks_full_mi\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot_multiple_datasets_correlations(df_comprehensive, COLS=SHM, metric=\"common/rougeLsum\", name=\"shmetrics_full_rouge\")\n",
    "# plot_multiple_datasets_correlations(df_comprehensive, COLS=classification_tasks,metric=\"common/rougeLsum\", name=\"classification_tasks_full_rouge\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12269da2762a8da5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_classification_tasks_proba_kl(df, dataset, legend=False, metric=\"I(summary -> text)\"):\n",
    "    df = df[~df['metadata/Decoding config'].str.contains(\"short\")].copy()\n",
    "    df = df[df['metadata/Dataset name'] == dataset]\n",
    "\n",
    "    df = df[~df['metadata/Decoding config'].isin([f\"beam_sampling_{k}\" for k in [5, 10, 20, 50]])]\n",
    "\n",
    "    map_tasks = {\"mrm8488_distilroberta-finetuned-financial-news-sentiment-analysis\": \"Sentiment analysis\",\n",
    "                 \"roberta-base-openai-detector\": \"GPT detector\",\n",
    "                 \"manifesto-project_manifestoberta-xlm-roberta-56policy-topics-context-2023-1-1\" : \"Topic classification\",\n",
    "                 }\n",
    "\n",
    "    # select only the tasks we want\n",
    "\n",
    "    # create a discrete sequential color palette with viridis\n",
    "\n",
    "    def custom_reg_plot(data, x=None, y=None, hue=None, ax=None, **kwargs):\n",
    "        sns.regplot(data=data, x=x, y=y, ci=None, scatter=False, ax=ax, x_ci='sd', line_kws={'linewidth': 5, 'alpha' : 0.5})\n",
    "        sns.scatterplot(data=data, x=x, y=y, hue=hue, alpha=1, s=500, ax=ax, **kwargs, palette=\"tab10\")\n",
    "        return ax\n",
    "\n",
    "    fig, axes = plt.subplots(len(map_tasks), 2, figsize=(10, 12), sharey=False, sharex=True, dpi=300)\n",
    "\n",
    "    for tidx, task in enumerate(map_tasks.keys()):\n",
    "        topplot = df\n",
    "        # rename columns\n",
    "        topplot = topplot.rename(\n",
    "            columns={\"metadata/Decoding size\": \"Decoding size\", \"metadata/Model name\": \"Model name\",\n",
    "                     \"metadata/Decoding config\": \"Decoding config\"})\n",
    "\n",
    "        custom_reg_plot(data=topplot, x=metric, y=f\"{task}/proba_of_error\", hue=\"Model name\",\n",
    "                        style='Model name', ax=axes[tidx, 0])\n",
    "        custom_reg_plot(data=topplot, x=metric, y=f\"{task}/kl\", hue=\"Model name\", style='Model name',\n",
    "                        ax=axes[tidx, 1])\n",
    "\n",
    "        # annotate with r value\n",
    "        axes[tidx, 0].annotate(f\"r={topplot[metric].corr(df[f'{task}/proba_of_error']):.2f}\",\n",
    "                               xy=(0.05, 0.2), xycoords='axes fraction', fontsize=12,\n",
    "                               horizontalalignment='left', verticalalignment='top')\n",
    "        axes[tidx, 1].annotate(f\"r={topplot[metric].corr(df[f'{task}/kl']):.2f}\", xy=(0.05, 0.1),\n",
    "                               xycoords='axes fraction', fontsize=12, )\n",
    "\n",
    "        # add title\n",
    "        axes[tidx, 0].set_title(map_tasks[task], fontsize=20, fontweight='bold')\n",
    "        axes[tidx, 1].set_title(map_tasks[task], fontsize=20, fontweight='bold')\n",
    "\n",
    "        # add y label\n",
    "        axes[tidx, 0].set_ylabel(\"P(error)\", fontsize=16, fontweight='bold')\n",
    "        axes[tidx, 1].set_ylabel(\"KL\", fontsize=16, fontweight='bold')\n",
    "\n",
    "        # remove x label:\n",
    "        axes[tidx, 0].set_xlabel(\"\")\n",
    "        axes[tidx, 1].set_xlabel(\"\")\n",
    "        \n",
    "        # make tick labels bigger\n",
    "        axes[tidx, 0].tick_params(axis='x', labelsize=16)\n",
    "        axes[tidx, 1].tick_params(axis='x', labelsize=16)\n",
    "        \n",
    "        axes[tidx, 0].tick_params(axis='y', labelsize=16)\n",
    "        axes[tidx, 1].tick_params(axis='y', labelsize=16)\n",
    "         \n",
    "        axes[tidx, 0].grid(True, which='both', axis='both', linestyle='--')\n",
    "        axes[tidx, 1].grid(True, which='both', axis='both', linestyle='--')\n",
    "\n",
    "    # add global legend\n",
    "    handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "    # fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.35), ncol=2, fontsize=16)\n",
    "    # remove all legends\n",
    "    for ax in axes.flatten():\n",
    "        ax.get_legend().remove()\n",
    "        \n",
    "    if legend:\n",
    "        fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.20), ncol=2, fontsize=16)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # save figure\n",
    "    path = f\"../../../papers/Mutual-information-for-summarization/img/classification_tasks/{SUBSET_NAME}_{EMBEDDER_NAME}_{dataset}_{metric}_classification_tasks_full.png\"\n",
    "    # create parent\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fig.savefig(path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plot_classification_tasks_proba_kl(df_comprehensive, dataset=\"cnn_dailymail\")\n",
    "# plot_classification_tasks_proba_kl(df_comprehensive, dataset=\"rotten_tomatoes\")\n",
    "\n",
    "plot_classification_tasks_proba_kl(df_comprehensive, dataset=\"xsum\")\n",
    "plot_classification_tasks_proba_kl(df_comprehensive, dataset=\"multi_news\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb6a7af0fea65afc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def plot_classification_tasks_proba(df, legend=False):\n",
    "    df = df[~df['metadata/Decoding config'].str.contains(\"short\")].copy()\n",
    "    df = df[~df['metadata/Dataset name'].str.contains('rotten')]\n",
    "\n",
    "\n",
    "    map_tasks = {\"mrm8488_distilroberta-finetuned-financial-news-sentiment-analysis\": \"Sentiment analysis\",\n",
    "                 \"roberta-base-openai-detector\": \"GPT detector\",\n",
    "                 \"manifesto-project_manifestoberta-xlm-roberta-56policy-topics-context-2023-1-1\" : \"Topic classification\",\n",
    "                 }\n",
    "    \n",
    "    tasks = [c + \"/proba_of_error\" for c in map_tasks.keys()]\n",
    "    \n",
    "    ddf =pd.melt(df, id_vars=['metadata/Model name', 'metadata/Dataset name', 'metadata/#params', 'I(summary -> text)'], value_vars=tasks, var_name='Task', value_name='P(error)')\n",
    "    ddf = ddf.rename(columns={'metadata/Model name': 'Model', 'metadata/Dataset name': 'Dataset', 'metadata/#params': '#params'})\n",
    "    ddf['Task'] = ddf['Task'].map(lambda x: x.split('/')[0])\n",
    "    ddf['Task'] = ddf['Task'].map(lambda x: map_tasks[x])\n",
    "    \n",
    "    # legend below\n",
    "    g = sns.relplot(data=ddf, x=\"I(summary -> text)\", y=\"P(error)\", hue=\"Model\", style='Model', col=\"Task\", row=\"Dataset\", height=3, aspect=0.7, palette='tab10', facet_kws={'sharey': False, 'sharex': False, 'margin_titles':True}, s=500)\n",
    "    \n",
    "    # add regression line\n",
    "    g.map(sns.regplot, \"I(summary -> text)\", \"P(error)\", scatter=False, ci=0.95, line_kws={'linewidth': 10, 'alpha': 0.5})\n",
    "    \n",
    "    # make title bigger\n",
    "    #g.fig.suptitle(\"Probability of error vs $I(T,S)$\", fontsize=20, fontweight='bold')\n",
    "    \n",
    "    # Column title format \n",
    "    g.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\", size=20, fontweight='bold')\n",
    "    \n",
    "    # make ylabels bigger\n",
    "    g.set_ylabels(\"P(error)\", fontsize=20, fontweight='bold')\n",
    "    \n",
    "    # make xlabels bigger\n",
    "    g.set_xlabels(\"$I(T;S)$\", fontsize=20, fontweight='bold')\n",
    "    \n",
    "    sns.move_legend(g, \"lower center\", bbox_to_anchor=(0.6, -0.3), ncol=2, fontsize=16)\n",
    "    \n",
    "\n",
    "    # save figure\n",
    "    path = f\"../../../papers/Mutual-information-for-summarization/img/classification_tasks/{SUBSET_NAME}_{EMBEDDER_NAME}_classification_tasks_full_proba.png\"\n",
    "    # create parent\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    g.fig.tight_layout()\n",
    "\n",
    "    g.fig.savefig(path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plot_classification_tasks_proba(df_comprehensive)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4555be221c6366a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9031c851112bb53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6cbe280377d67c84"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_model_comparison(df):\n",
    "    df = df.copy()\n",
    "    # remove dataset rotten tomatoes\n",
    "    df = df[df['metadata/Dataset name'] != 'rotten_tomatoes']\n",
    "    \n",
    "    # remove first part of model name\n",
    "    df['metadata/Model name'] = df['metadata/Model name'].apply(lambda x: \" \".join(x.split('/')[1:]))\n",
    "\n",
    "    def replace_model_name(x):\n",
    "        if \"text_summarization\" in x:\n",
    "            return \"Falcon AI text\"\n",
    "        elif \"medical\" in x:\n",
    "            return \"Falcon AI medical\"\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    df['metadata/Model name'] = df['metadata/Model name'].apply(replace_model_name)\n",
    "    # sort by model size\n",
    "    df = df.sort_values(by=['metadata/#params'])\n",
    "    ax = sns.barplot(data=df, x='metadata/Model name', y='I(summary -> text)', hue='metadata/Dataset name', orient='v', palette='tab10')\n",
    "    \n",
    "    # twin axes x with model size\n",
    "    ax2 = plt.twinx()\n",
    "    # log scale\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    sns.barplot(data=df, x='metadata/Model name', y='metadata/#params', orient='v',  ax=ax2, alpha=0.6, color='grey')\n",
    "    \n",
    "    # make ylim 40, 60\n",
    "    ax.set_ylim(40, 60)\n",
    "    # ax.set_ylim(700, 820)\n",
    "    \n",
    "    # rotate x labels\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=80)\n",
    "    \n",
    "    # rename labels\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"$I(\\\\mathbf{T};\\\\mathbf{S})$\", fontsize=20, )\n",
    "    ax2.set_ylabel(\"Size\", fontsize=20)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # add vertical lines for the best model on each dataset\n",
    "    for didx, dataset in enumerate(reversed(['xsum', 'cnn_dailymail', 'multi_news'])):\n",
    "        best_model = df[df['metadata/Dataset name'] == dataset].sort_values(by='I(summary -> text)').iloc[-1]\n",
    "        ax.axhline(y=best_model['I(summary -> text)'], color=f'C{didx}', linestyle='--', alpha=1, linewidth=3)\n",
    "        \n",
    "        \n",
    "    # put legend outside top \n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=3, fontsize=16)\n",
    "\n",
    "    \n",
    "\n",
    "    # save figure\n",
    "    path = f\"../../../papers/Mutual-information-for-summarization/img/{SUBSET_NAME}_{EMBEDDER_NAME}_model_comparison.png\"\n",
    "    # create parent\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    fig = ax.get_figure()\n",
    "    # fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "plot_model_comparison(df_comprehensive)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f68bfa88c341b7b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df):\n",
    "    df = df.copy()\n",
    "    # remove dataset rotten tomatoes\n",
    "    df = df[df['metadata/Dataset name'] != 'rotten_tomatoes']\n",
    "    \n",
    "    # remove first part of model name\n",
    "    df['metadata/Model name'] = df['metadata/Model name'].apply(lambda x: \" \".join(x.split('/')[1:]))\n",
    "    \n",
    "    # sort by model size\n",
    "    df = df.sort_values(by=['metadata/#params'])\n",
    "    \n",
    "    # select only the columns we want\n",
    "    ROUGES = [\"common/rougeLsum\", \"common/BERTScore\", \"common/BARTScore\"]\n",
    "    MI = ['I(summary -> text)']\n",
    "    SHM = [c for c in df.columns if \"SHMetric\" in c and \"proba_1\" in c]\n",
    "    # keep only Attribution, Main idea, Conciseness\n",
    "    SHM = [c for c in SHM if \"Attribution\" in c or \"Main ideas\" in c or \"Conciseness\" in c]\n",
    "    \n",
    "\n",
    "    map_tasks = {\"mrm8488_distilroberta-finetuned-financial-news-sentiment-analysis\": \"Sentiment analysis\",\n",
    "                 \"roberta-base-openai-detector\": \"GPT detector\",\n",
    "                 \"manifesto-project_manifestoberta-xlm-roberta-56policy-topics-context-2023-1-1\" : \"Topic classification\",\n",
    "                 }\n",
    "    \n",
    "    classification_tasks_error = [c + \"/proba_of_error\" for c in map_tasks.keys()]\n",
    "    classification_tasks = [c + \"/proba_of_success\" for c in map_tasks.keys()]\n",
    "    \n",
    "    # make proba_of_error proba_of_success\n",
    "    df[classification_tasks] = 1 - df[classification_tasks_error]\n",
    "    classification_tasks = []\n",
    "    \n",
    "\n",
    "    def rename_metrics(x):\n",
    "        splits = x.split('/')\n",
    "\n",
    "        if len(splits) == 1:\n",
    "            if splits[0] == \"I(summary -> text)\":\n",
    "                return \"$I(T;S)$\"\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            if splits[0] in map_tasks.keys():\n",
    "                return map_tasks[splits[0]]\n",
    "            else:\n",
    "                if splits[1] == \"rougeLsum\":\n",
    "                    return \"ROUGE-L\"\n",
    "                else:\n",
    "                    return splits[1]\n",
    "\n",
    "    # select only the tasks we want\n",
    "    df = df[ROUGES + MI + SHM + classification_tasks]\n",
    "    \n",
    "    \n",
    "    # rename columns\n",
    "    df.columns = [rename_metrics(c) for c in df.columns]\n",
    "    \n",
    "    \n",
    "    corrs = df.corr(method='spearman')\n",
    "    \n",
    "    sns.set_theme(style=\"white\")\n",
    "    # fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    \n",
    "    mask = np.triu(np.ones_like(corrs, dtype=bool), k=1)\n",
    "    g = sns.clustermap(corrs, annot=True, cmap='Blues', robust=True, annot_kws={\"fontsize\": 16}, fmt='.1f', square=True)\n",
    "    \n",
    "    # make xtick labels bigger\n",
    "    g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xmajorticklabels(), fontsize = 16)\n",
    "    \n",
    "    # make ytick labels bigger\n",
    "    g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_ymajorticklabels(), fontsize = 16)\n",
    "    \n",
    "    \n",
    "    # save figure\n",
    "    path = f\"../../../papers/Mutual-information-for-summarization/img/{SUBSET_NAME}_{EMBEDDER_NAME}_correlation_matrix.png\"\n",
    "    # create parent\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    g.fig.tight_layout()\n",
    "    g.fig.savefig(path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "plot_correlation_matrix(df_comprehensive)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "503dc0c04248f81b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51a5f63e02f31487"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "98e8859403819754"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6aa753e2625943c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "63c46c7b4b5306aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5cc06ff7e784ab90"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1adfa1920a47cc9b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f77ce860fd4402f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b4c994e7b75b1c8f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7d5c094f9091b4dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a997ac0e5ca90dfb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e1857f7ac228758",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "10de9fb2bd8e380b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f631820cf3b2321f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c7de310b79aaad71",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "98903b36ec36bcbc",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
